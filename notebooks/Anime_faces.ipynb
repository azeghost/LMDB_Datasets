{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import lmdb\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/azeghost/git/lmdb_new/LMDB_Datasets\n"
     ]
    }
   ],
   "source": [
    "os.chdir('../') # adress to git dir\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformation.lmdb_transformer import LmdbTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store images in lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '/home/azeghost/git/datasets/.anime/anime-faces' #Folder to images\n",
    "validation_percentage = 30\n",
    "valid_format = ['jpg', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/azeghost/git/datasets/.anime/anime-faces'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'blazer'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m897 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'nishikino_maki'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1131 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'akemi_homura'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m802 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'monochrome'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m672 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'pink_hair'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1043 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'short_hair'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m904 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'smile'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1031 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'ayase_eli'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m975 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'hair_bow'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1028 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'blue_background'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m932 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'serafuku'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m998 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'aqua_hair'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1048 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'minami_kotori'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1217 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'earrings'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m852 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'purple_eyes'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m989 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'miyanaga_saki'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m581 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'aqua_eyes'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1054 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'sunglasses'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m847 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in '1girl'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m926 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'necklace'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m944 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'hoshizora_rin'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1103 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'kirisame_marisa'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m848 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'uniform'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m911 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'bow'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1027 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'comic'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m786 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'fate_testarossa'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1126 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'hair_ornament'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1032 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'santa_costume'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1105 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'yellow_eyes'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m912 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'twintails'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m859 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'white_hair'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m733 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'blonde_hair'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m967 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'blush'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1009 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'side_ponytail'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1057 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'collarbone'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1037 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in ':o'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1059 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'headphones'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m826 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'honma_meiko'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m603 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'dress'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m896 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'hat'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m985 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'japanese_clothes'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m700 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'nishizumi_miho'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m591 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'necktie'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m943 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'school_uniform'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m908 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'red_background'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m644 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'sweatdrop'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m903 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'sky'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m330 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'braid'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m977 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'tears'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m845 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'tomoe_mami'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m900 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in '1boy'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m528 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'cat_ears'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1026 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'black_background'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m397 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'hair_flower'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1113 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'ayanami_rei'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m900 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'nagato_yuki'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m979 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'emilia_(re:zero)'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m376 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'yazawa_nico'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1102 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'simple_background'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m944 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'white_background'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m974 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'pointy_ears'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m351 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'purple_hair'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m961 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'looking_at_viewer'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m988 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'hair_ribbon'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m985 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'swimsuit'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1040 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'bunny_ears'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1049 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'scarf'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m852 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'red_eyes'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m976 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'red_hair'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m919 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'night'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m558 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'blue_eyes'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m970 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in ':d'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1152 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'green_eyes'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1000 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'closed_eyes'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m839 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'flower'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1011 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'hairclip'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1025 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'maid'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1030 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'silver_hair'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m900 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'magical_girl'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m973 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'rem_(re:zero)'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m821 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'glasses'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m900 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'hakurei_reimu'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m747 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'choker'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m938 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'kousaka_honoka'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1226 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'breasts'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m948 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'souryuu_asuka_langley'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m674 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'hairband'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m947 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'frills'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1063 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'akaza_akari'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1141 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'green_hair'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1027 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'brown_eyes'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1000 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'ahoge'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1020 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'military'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m797 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'toujou_nozomi'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1137 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'tongue'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m566 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'water'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m788 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'speech_bubble'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m875 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'blue_hair'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1012 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'kaname_madoka'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m936 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'looking_back'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m718 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'brown_hair'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m763 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'witch_hat'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m805 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'one_eye_closed'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1077 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'cape'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m791 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'sonoda_umi'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1067 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'tongue_out'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m818 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'kimono'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1002 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'underwear'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m914 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'animal_ears'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1003 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'koizumi_hanayo'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1121 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'ribbon'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m982 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'black_hair'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m912 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'apron'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1097 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'suzumiya_haruhi'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m637 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'miki_sayaka'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m966 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'sweat'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m838 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'open_mouth'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1035 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'armor'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m669 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'pink_eyes'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1032 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'orange_hair'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1021 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'misaka_mikoto'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1114 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'long_hair'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m965 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'ponytail'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m917 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'black_eyes'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m954 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'bare_shoulders'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m935 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'very_long_hair'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m958 file found\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer = LmdbTransformer(image_dir = images_dir, \n",
    "                              validation_pct = validation_percentage, valid_image_formats = valid_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /home/azeghost/git/lmdb_new/LMDB_Datasets/.data/Pokemon_LMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {\n",
    "    'Dataset_name': \"Anime_Faces\",\n",
    "    'Dataset_size': 115085,\n",
    "    'val_num_images':34591,\n",
    "    'tra_num_images' : 80494\n",
    "}\n",
    "\n",
    "transformer.save_metadata('/home/azeghost/git/lmdb_new/LMDB_Datasets/.data/Anime_Faces_LMDB',info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dataset_name': 'Anime_Faces',\n",
       " 'Dataset_size': 115085,\n",
       " 'val_num_images': 34591,\n",
       " 'tra_num_images': 80494}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.get_metadata('/home/azeghost/git/lmdb_new/LMDB_Datasets/.data/Anime_Faces_LMDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets_customed.label_by_filename import get_label_by_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_label_by_filename(img_path):\n",
    "    name, _ = os.path.splitext(img_path)\n",
    "    vid_img_arr = name.split(sep=os.sep)[-1:]\n",
    "    return {'label': (vid_img_arr)[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of imgs for catagory80494\n",
      "Storing 650.data/Anime_Faces_LMDB/_training_blazer\n",
      "Storing 785.data/Anime_Faces_LMDB/_training_nishikino maki\n",
      "Storing 545.data/Anime_Faces_LMDB/_training_akemi homura\n",
      "Storing 470.data/Anime_Faces_LMDB/_training_monochrome\n",
      "Storing 738.data/Anime_Faces_LMDB/_training_pink hair\n",
      "Storing 635.data/Anime_Faces_LMDB/_training_short hair\n",
      "Storing 706.data/Anime_Faces_LMDB/_training_smile\n",
      "Storing 715.data/Anime_Faces_LMDB/_training_ayase eli\n",
      "Storing 719.data/Anime_Faces_LMDB/_training_hair bow\n",
      "Storing 635.data/Anime_Faces_LMDB/_training_blue background\n",
      "Storing 679.data/Anime_Faces_LMDB/_training_serafuku\n",
      "Storing 726.data/Anime_Faces_LMDB/_training_aqua hair\n",
      "Storing 859.data/Anime_Faces_LMDB/_training_minami kotori\n",
      "Storing 604.data/Anime_Faces_LMDB/_training_earrings\n",
      "Storing 683.data/Anime_Faces_LMDB/_training_purple eyes\n",
      "Storing 411.data/Anime_Faces_LMDB/_training_miyanaga saki\n",
      "Storing 718.data/Anime_Faces_LMDB/_training_aqua eyes\n",
      "Storing 609.data/Anime_Faces_LMDB/_training_sunglasses\n",
      "Storing 642.data/Anime_Faces_LMDB/_training_1girl\n",
      "Storing 642.data/Anime_Faces_LMDB/_training_necklace\n",
      "Storing 769.data/Anime_Faces_LMDB/_training_hoshizora rin\n",
      "Storing 589.data/Anime_Faces_LMDB/_training_kirisame marisa\n",
      "Storing 649.data/Anime_Faces_LMDB/_training_uniform\n",
      "Storing 736.data/Anime_Faces_LMDB/_training_bow\n",
      "Storing 561.data/Anime_Faces_LMDB/_training_comic\n",
      "Storing 778.data/Anime_Faces_LMDB/_training_fate testarossa\n",
      "Storing 726.data/Anime_Faces_LMDB/_training_hair ornament\n",
      "Storing 777.data/Anime_Faces_LMDB/_training_santa costume\n",
      "Storing 639.data/Anime_Faces_LMDB/_training_yellow eyes\n",
      "Storing 587.data/Anime_Faces_LMDB/_training_twintails\n",
      "Storing 510.data/Anime_Faces_LMDB/_training_white hair\n",
      "Storing 661.data/Anime_Faces_LMDB/_training_blonde hair\n",
      "Storing 735.data/Anime_Faces_LMDB/_training_blush\n",
      "Storing 745.data/Anime_Faces_LMDB/_training_side ponytail\n",
      "Storing 729.data/Anime_Faces_LMDB/_training_collarbone\n",
      "Storing 742.data/Anime_Faces_LMDB/_training_ o\n",
      "Storing 570.data/Anime_Faces_LMDB/_training_headphones\n",
      "Storing 435.data/Anime_Faces_LMDB/_training_honma meiko\n",
      "Storing 607.data/Anime_Faces_LMDB/_training_dress\n",
      "Storing 691.data/Anime_Faces_LMDB/_training_hat\n",
      "Storing 482.data/Anime_Faces_LMDB/_training_japanese clothes\n",
      "Storing 412.data/Anime_Faces_LMDB/_training_nishizumi miho\n",
      "Storing 669.data/Anime_Faces_LMDB/_training_necktie\n",
      "Storing 613.data/Anime_Faces_LMDB/_training_school uniform\n",
      "Storing 458.data/Anime_Faces_LMDB/_training_red background\n",
      "Storing 643.data/Anime_Faces_LMDB/_training_sweatdrop\n",
      "Storing 236.data/Anime_Faces_LMDB/_training_sky\n",
      "Storing 655.data/Anime_Faces_LMDB/_training_braid\n",
      "Storing 585.data/Anime_Faces_LMDB/_training_tears\n",
      "Storing 600.data/Anime_Faces_LMDB/_training_tomoe mami\n",
      "Storing 372.data/Anime_Faces_LMDB/_training_1boy\n",
      "Storing 721.data/Anime_Faces_LMDB/_training_cat ears\n",
      "Storing 297.data/Anime_Faces_LMDB/_training_black background\n",
      "Storing 797.data/Anime_Faces_LMDB/_training_hair flower\n",
      "Storing 651.data/Anime_Faces_LMDB/_training_ayanami rei\n",
      "Storing 703.data/Anime_Faces_LMDB/_training_nagato yuki\n",
      "Storing 272.data/Anime_Faces_LMDB/_training_emilia re zero \n",
      "Storing 791.data/Anime_Faces_LMDB/_training_yazawa nico\n",
      "Storing 665.data/Anime_Faces_LMDB/_training_simple background\n",
      "Storing 681.data/Anime_Faces_LMDB/_training_white background\n",
      "Storing 252.data/Anime_Faces_LMDB/_training_pointy ears\n",
      "Storing 654.data/Anime_Faces_LMDB/_training_purple hair\n",
      "Storing 700.data/Anime_Faces_LMDB/_training_looking at viewer\n",
      "Storing 680.data/Anime_Faces_LMDB/_training_hair ribbon\n",
      "Storing 707.data/Anime_Faces_LMDB/_training_swimsuit\n",
      "Storing 733.data/Anime_Faces_LMDB/_training_bunny ears\n",
      "Storing 599.data/Anime_Faces_LMDB/_training_scarf\n",
      "Storing 673.data/Anime_Faces_LMDB/_training_red eyes\n",
      "Storing 636.data/Anime_Faces_LMDB/_training_red hair\n",
      "Storing 405.data/Anime_Faces_LMDB/_training_night\n",
      "Storing 665.data/Anime_Faces_LMDB/_training_blue eyes\n",
      "Storing 789.data/Anime_Faces_LMDB/_training_ d\n",
      "Storing 721.data/Anime_Faces_LMDB/_training_green eyes\n",
      "Storing 597.data/Anime_Faces_LMDB/_training_closed eyes\n",
      "Storing 710.data/Anime_Faces_LMDB/_training_flower\n",
      "Storing 711.data/Anime_Faces_LMDB/_training_hairclip\n",
      "Storing 706.data/Anime_Faces_LMDB/_training_maid\n",
      "Storing 611.data/Anime_Faces_LMDB/_training_silver hair\n",
      "Storing 675.data/Anime_Faces_LMDB/_training_magical girl\n",
      "Storing 584.data/Anime_Faces_LMDB/_training_rem re zero \n",
      "Storing 620.data/Anime_Faces_LMDB/_training_glasses\n",
      "Storing 532.data/Anime_Faces_LMDB/_training_hakurei reimu\n",
      "Storing 657.data/Anime_Faces_LMDB/_training_choker\n",
      "Storing 853.data/Anime_Faces_LMDB/_training_kousaka honoka\n",
      "Storing 664.data/Anime_Faces_LMDB/_training_breasts\n",
      "Storing 475.data/Anime_Faces_LMDB/_training_souryuu asuka langley\n",
      "Storing 648.data/Anime_Faces_LMDB/_training_hairband\n",
      "Storing 755.data/Anime_Faces_LMDB/_training_frills\n",
      "Storing 796.data/Anime_Faces_LMDB/_training_akaza akari\n",
      "Storing 728.data/Anime_Faces_LMDB/_training_green hair\n",
      "Storing 720.data/Anime_Faces_LMDB/_training_brown eyes\n",
      "Storing 706.data/Anime_Faces_LMDB/_training_ahoge\n",
      "Storing 566.data/Anime_Faces_LMDB/_training_military\n",
      "Storing 813.data/Anime_Faces_LMDB/_training_toujou nozomi\n",
      "Storing 405.data/Anime_Faces_LMDB/_training_tongue\n",
      "Storing 557.data/Anime_Faces_LMDB/_training_water\n",
      "Storing 603.data/Anime_Faces_LMDB/_training_speech bubble\n",
      "Storing 705.data/Anime_Faces_LMDB/_training_blue hair\n",
      "Storing 619.data/Anime_Faces_LMDB/_training_kaname madoka\n",
      "Storing 494.data/Anime_Faces_LMDB/_training_looking back\n",
      "Storing 528.data/Anime_Faces_LMDB/_training_brown hair\n",
      "Storing 570.data/Anime_Faces_LMDB/_training_witch hat\n",
      "Storing 752.data/Anime_Faces_LMDB/_training_one eye closed\n",
      "Storing 568.data/Anime_Faces_LMDB/_training_cape\n",
      "Storing 781.data/Anime_Faces_LMDB/_training_sonoda umi\n",
      "Storing 582.data/Anime_Faces_LMDB/_training_tongue out\n",
      "Storing 712.data/Anime_Faces_LMDB/_training_kimono\n",
      "Storing 640.data/Anime_Faces_LMDB/_training_underwear\n",
      "Storing 716.data/Anime_Faces_LMDB/_training_animal ears\n",
      "Storing 798.data/Anime_Faces_LMDB/_training_koizumi hanayo\n",
      "Storing 692.data/Anime_Faces_LMDB/_training_ribbon\n",
      "Storing 634.data/Anime_Faces_LMDB/_training_black hair\n",
      "Storing 733.data/Anime_Faces_LMDB/_training_apron\n",
      "Storing 465.data/Anime_Faces_LMDB/_training_suzumiya haruhi\n",
      "Storing 646.data/Anime_Faces_LMDB/_training_miki sayaka\n",
      "Storing 575.data/Anime_Faces_LMDB/_training_sweat\n",
      "Storing 717.data/Anime_Faces_LMDB/_training_open mouth\n",
      "Storing 466.data/Anime_Faces_LMDB/_training_armor\n",
      "Storing 740.data/Anime_Faces_LMDB/_training_pink eyes\n",
      "Storing 702.data/Anime_Faces_LMDB/_training_orange hair\n",
      "Storing 772.data/Anime_Faces_LMDB/_training_misaka mikoto\n",
      "Storing 675.data/Anime_Faces_LMDB/_training_long hair\n",
      "Storing 654.data/Anime_Faces_LMDB/_training_ponytail\n",
      "Storing 628.data/Anime_Faces_LMDB/_training_black eyes\n",
      "Storing 651.data/Anime_Faces_LMDB/_training_bare shoulders\n",
      "Storing 663.data/Anime_Faces_LMDB/_training_very long hair\n"
     ]
    }
   ],
   "source": [
    "transformer.transform_store(labels_fn=get_label_by_filename,image_dir=images_dir, lmdb_dir = '.data/Anime_Faces_LMDB'\n",
    "           ,category='training',target_size=(100,100),color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of imgs for catagory34591\n",
      "Storing 247.data/Anime_Faces_LMDB/_validation_blazer\n",
      "Storing 346.data/Anime_Faces_LMDB/_validation_nishikino maki\n",
      "Storing 257.data/Anime_Faces_LMDB/_validation_akemi homura\n",
      "Storing 202.data/Anime_Faces_LMDB/_validation_monochrome\n",
      "Storing 305.data/Anime_Faces_LMDB/_validation_pink hair\n",
      "Storing 269.data/Anime_Faces_LMDB/_validation_short hair\n",
      "Storing 325.data/Anime_Faces_LMDB/_validation_smile\n",
      "Storing 260.data/Anime_Faces_LMDB/_validation_ayase eli\n",
      "Storing 309.data/Anime_Faces_LMDB/_validation_hair bow\n",
      "Storing 297.data/Anime_Faces_LMDB/_validation_blue background\n",
      "Storing 319.data/Anime_Faces_LMDB/_validation_serafuku\n",
      "Storing 322.data/Anime_Faces_LMDB/_validation_aqua hair\n",
      "Storing 358.data/Anime_Faces_LMDB/_validation_minami kotori\n",
      "Storing 248.data/Anime_Faces_LMDB/_validation_earrings\n",
      "Storing 306.data/Anime_Faces_LMDB/_validation_purple eyes\n",
      "Storing 170.data/Anime_Faces_LMDB/_validation_miyanaga saki\n",
      "Storing 336.data/Anime_Faces_LMDB/_validation_aqua eyes\n",
      "Storing 238.data/Anime_Faces_LMDB/_validation_sunglasses\n",
      "Storing 284.data/Anime_Faces_LMDB/_validation_1girl\n",
      "Storing 302.data/Anime_Faces_LMDB/_validation_necklace\n",
      "Storing 334.data/Anime_Faces_LMDB/_validation_hoshizora rin\n",
      "Storing 259.data/Anime_Faces_LMDB/_validation_kirisame marisa\n",
      "Storing 262.data/Anime_Faces_LMDB/_validation_uniform\n",
      "Storing 291.data/Anime_Faces_LMDB/_validation_bow\n",
      "Storing 225.data/Anime_Faces_LMDB/_validation_comic\n",
      "Storing 348.data/Anime_Faces_LMDB/_validation_fate testarossa\n",
      "Storing 306.data/Anime_Faces_LMDB/_validation_hair ornament\n",
      "Storing 328.data/Anime_Faces_LMDB/_validation_santa costume\n",
      "Storing 273.data/Anime_Faces_LMDB/_validation_yellow eyes\n",
      "Storing 272.data/Anime_Faces_LMDB/_validation_twintails\n",
      "Storing 223.data/Anime_Faces_LMDB/_validation_white hair\n",
      "Storing 306.data/Anime_Faces_LMDB/_validation_blonde hair\n",
      "Storing 274.data/Anime_Faces_LMDB/_validation_blush\n",
      "Storing 312.data/Anime_Faces_LMDB/_validation_side ponytail\n",
      "Storing 308.data/Anime_Faces_LMDB/_validation_collarbone\n",
      "Storing 317.data/Anime_Faces_LMDB/_validation_ o\n",
      "Storing 256.data/Anime_Faces_LMDB/_validation_headphones\n",
      "Storing 168.data/Anime_Faces_LMDB/_validation_honma meiko\n",
      "Storing 289.data/Anime_Faces_LMDB/_validation_dress\n",
      "Storing 294.data/Anime_Faces_LMDB/_validation_hat\n",
      "Storing 218.data/Anime_Faces_LMDB/_validation_japanese clothes\n",
      "Storing 179.data/Anime_Faces_LMDB/_validation_nishizumi miho\n",
      "Storing 274.data/Anime_Faces_LMDB/_validation_necktie\n",
      "Storing 295.data/Anime_Faces_LMDB/_validation_school uniform\n",
      "Storing 186.data/Anime_Faces_LMDB/_validation_red background\n",
      "Storing 260.data/Anime_Faces_LMDB/_validation_sweatdrop\n",
      "Storing 94.data/Anime_Faces_LMDB/_validation_sky\n",
      "Storing 322.data/Anime_Faces_LMDB/_validation_braid\n",
      "Storing 260.data/Anime_Faces_LMDB/_validation_tears\n",
      "Storing 300.data/Anime_Faces_LMDB/_validation_tomoe mami\n",
      "Storing 156.data/Anime_Faces_LMDB/_validation_1boy\n",
      "Storing 305.data/Anime_Faces_LMDB/_validation_cat ears\n",
      "Storing 100.data/Anime_Faces_LMDB/_validation_black background\n",
      "Storing 316.data/Anime_Faces_LMDB/_validation_hair flower\n",
      "Storing 249.data/Anime_Faces_LMDB/_validation_ayanami rei\n",
      "Storing 276.data/Anime_Faces_LMDB/_validation_nagato yuki\n",
      "Storing 104.data/Anime_Faces_LMDB/_validation_emilia re zero \n",
      "Storing 311.data/Anime_Faces_LMDB/_validation_yazawa nico\n",
      "Storing 279.data/Anime_Faces_LMDB/_validation_simple background\n",
      "Storing 293.data/Anime_Faces_LMDB/_validation_white background\n",
      "Storing 99.data/Anime_Faces_LMDB/_validation_pointy ears\n",
      "Storing 307.data/Anime_Faces_LMDB/_validation_purple hair\n",
      "Storing 288.data/Anime_Faces_LMDB/_validation_looking at viewer\n",
      "Storing 305.data/Anime_Faces_LMDB/_validation_hair ribbon\n",
      "Storing 333.data/Anime_Faces_LMDB/_validation_swimsuit\n",
      "Storing 316.data/Anime_Faces_LMDB/_validation_bunny ears\n",
      "Storing 253.data/Anime_Faces_LMDB/_validation_scarf\n",
      "Storing 303.data/Anime_Faces_LMDB/_validation_red eyes\n",
      "Storing 283.data/Anime_Faces_LMDB/_validation_red hair\n",
      "Storing 153.data/Anime_Faces_LMDB/_validation_night\n",
      "Storing 305.data/Anime_Faces_LMDB/_validation_blue eyes\n",
      "Storing 363.data/Anime_Faces_LMDB/_validation_ d\n",
      "Storing 279.data/Anime_Faces_LMDB/_validation_green eyes\n",
      "Storing 242.data/Anime_Faces_LMDB/_validation_closed eyes\n",
      "Storing 301.data/Anime_Faces_LMDB/_validation_flower\n",
      "Storing 314.data/Anime_Faces_LMDB/_validation_hairclip\n",
      "Storing 324.data/Anime_Faces_LMDB/_validation_maid\n",
      "Storing 289.data/Anime_Faces_LMDB/_validation_silver hair\n",
      "Storing 298.data/Anime_Faces_LMDB/_validation_magical girl\n",
      "Storing 237.data/Anime_Faces_LMDB/_validation_rem re zero \n",
      "Storing 280.data/Anime_Faces_LMDB/_validation_glasses\n",
      "Storing 215.data/Anime_Faces_LMDB/_validation_hakurei reimu\n",
      "Storing 281.data/Anime_Faces_LMDB/_validation_choker\n",
      "Storing 373.data/Anime_Faces_LMDB/_validation_kousaka honoka\n",
      "Storing 284.data/Anime_Faces_LMDB/_validation_breasts\n",
      "Storing 199.data/Anime_Faces_LMDB/_validation_souryuu asuka langley\n",
      "Storing 299.data/Anime_Faces_LMDB/_validation_hairband\n",
      "Storing 308.data/Anime_Faces_LMDB/_validation_frills\n",
      "Storing 345.data/Anime_Faces_LMDB/_validation_akaza akari\n",
      "Storing 299.data/Anime_Faces_LMDB/_validation_green hair\n",
      "Storing 280.data/Anime_Faces_LMDB/_validation_brown eyes\n",
      "Storing 314.data/Anime_Faces_LMDB/_validation_ahoge\n",
      "Storing 231.data/Anime_Faces_LMDB/_validation_military\n",
      "Storing 324.data/Anime_Faces_LMDB/_validation_toujou nozomi\n",
      "Storing 161.data/Anime_Faces_LMDB/_validation_tongue\n",
      "Storing 231.data/Anime_Faces_LMDB/_validation_water\n",
      "Storing 272.data/Anime_Faces_LMDB/_validation_speech bubble\n",
      "Storing 307.data/Anime_Faces_LMDB/_validation_blue hair\n",
      "Storing 317.data/Anime_Faces_LMDB/_validation_kaname madoka\n",
      "Storing 224.data/Anime_Faces_LMDB/_validation_looking back\n",
      "Storing 235.data/Anime_Faces_LMDB/_validation_brown hair\n",
      "Storing 235.data/Anime_Faces_LMDB/_validation_witch hat\n",
      "Storing 325.data/Anime_Faces_LMDB/_validation_one eye closed\n",
      "Storing 223.data/Anime_Faces_LMDB/_validation_cape\n",
      "Storing 286.data/Anime_Faces_LMDB/_validation_sonoda umi\n",
      "Storing 236.data/Anime_Faces_LMDB/_validation_tongue out\n",
      "Storing 290.data/Anime_Faces_LMDB/_validation_kimono\n",
      "Storing 274.data/Anime_Faces_LMDB/_validation_underwear\n",
      "Storing 287.data/Anime_Faces_LMDB/_validation_animal ears\n",
      "Storing 323.data/Anime_Faces_LMDB/_validation_koizumi hanayo\n",
      "Storing 290.data/Anime_Faces_LMDB/_validation_ribbon\n",
      "Storing 278.data/Anime_Faces_LMDB/_validation_black hair\n",
      "Storing 364.data/Anime_Faces_LMDB/_validation_apron\n",
      "Storing 172.data/Anime_Faces_LMDB/_validation_suzumiya haruhi\n",
      "Storing 320.data/Anime_Faces_LMDB/_validation_miki sayaka\n",
      "Storing 263.data/Anime_Faces_LMDB/_validation_sweat\n",
      "Storing 318.data/Anime_Faces_LMDB/_validation_open mouth\n",
      "Storing 203.data/Anime_Faces_LMDB/_validation_armor\n",
      "Storing 292.data/Anime_Faces_LMDB/_validation_pink eyes\n",
      "Storing 319.data/Anime_Faces_LMDB/_validation_orange hair\n",
      "Storing 342.data/Anime_Faces_LMDB/_validation_misaka mikoto\n",
      "Storing 290.data/Anime_Faces_LMDB/_validation_long hair\n",
      "Storing 263.data/Anime_Faces_LMDB/_validation_ponytail\n",
      "Storing 326.data/Anime_Faces_LMDB/_validation_black eyes\n",
      "Storing 284.data/Anime_Faces_LMDB/_validation_bare shoulders\n",
      "Storing 295.data/Anime_Faces_LMDB/_validation_very long hair\n"
     ]
    }
   ],
   "source": [
    "transformer.transform_store(labels_fn=get_label_by_filename,image_dir=images_dir, lmdb_dir = '.data/Anime_Faces_LMDB'\n",
    "           ,category='validation',target_size=(100,100),color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdasdasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la .data/Anime_Faces_LMDB/_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the lmdb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Todo\n",
    " - Env put outside of loops for write and read\n",
    " - Try the Dynamic code again with clean kernel \n",
    " - Create Standartize as an option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "import pickle\n",
    "\n",
    "def read_many_lmdb(lmdb_dir, num_images):\n",
    "\n",
    "    images, labels = [], {}\n",
    "    env = lmdb.open(lmdb_dir, readonly=True)\n",
    "\n",
    "    # Start a new read transaction\n",
    "    with env.begin() as txn:\n",
    "        # Read all images in one single transaction, with one lock\n",
    "        # We could split this up into multiple transactions if needed\n",
    "        for image_id in range(num_images):\n",
    "            data = txn.get(f\"{image_id:08}\".encode(\"ascii\"))\n",
    "            # Remember that it's a CIFAR_Image object \n",
    "            # that is stored as the value\n",
    "            dataset = pickle.loads(data)\n",
    "            images.append(dataset.get_image())\n",
    "            \n",
    "            labels_list = [attr for attr in dir(dataset) if not callable(getattr(dataset, attr)) and (not attr.startswith(\"__\")) and \n",
    "                           (not attr in ['image','channels',  'size'] )]\n",
    "\n",
    "            for label in labels_list:\n",
    "                # _lab = {label: eval(f'dataset.{label}')}\n",
    "#                 print({label: eval(f'dataset.{label}')})\n",
    "                # labels = {**labels, **_lab}\n",
    "                if label in labels:\n",
    "                    labels[label].append(eval(f'dataset.{label}'))\n",
    "                else:\n",
    "                    labels = {label: [eval(f'dataset.{label}')] }\n",
    "                \n",
    "    env.close()\n",
    "    return {'images': images, **labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-15a5afe6dabb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_many_lmdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/azeghost/git/lmdb_new/LMDB_Datasets/.data/Anime_Faces_LMDB/_training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-f190a748af2a>\u001b[0m in \u001b[0;36mread_many_lmdb\u001b[0;34m(lmdb_dir, num_images)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Remember that it's a CIFAR_Image object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# that is stored as the value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "ds = read_many_lmdb('/home/azeghost/git/lmdb_new/LMDB_Datasets/.data/Anime_Faces_LMDB/_training', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds['images'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ad = np.array(ds)\n",
    "ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(ds['images']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(ds['label']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k, val in ds:\n",
    "    print(k,str(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['label'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip and upload to git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/azeghost/git/lmdb_new/LMDB_Datasets/.data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -cvjf pokemon.tar.bz Pokemon_LMDB/* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!split -b 50M pokemon.tar.bz \"pokemon.tar.part\"\n",
    "#split -b <max size> <name of zip or dir to zip/name> <split file name beginning>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if they are created\n",
    "!ls -lh pokemon.tar.part*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move to correct folder and push to git\n",
    "# !mkdir /home/azeghost/git/LMDB_Datasets/pokemon\n",
    "# !mv pokemon.tar.part* /home/azeghost/git/Generative_Models/data/.pokemon\n",
    "# !ls -la /home/azeghost/git/Generative_Models/data/.pokemon "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pokemon_training\n",
    "!cat pokemon.tar.part* > pokemon_combined.tar.bz\n",
    "#!cat <split files put * at the end> > <final zip name>\n",
    "!ls -la \n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tar -xf pokemon_combined.tar.bz --directory ./.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls -la ./.test/Pokemon_LMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf ./.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMDBImageIterator and LMDBImageGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/azeghost/git/Generative_Models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import Iterator, load_img, img_to_array, array_to_img\n",
    "from keras import backend as K\n",
    "import logging\n",
    "from utils.reporting.logging import log_message\n",
    "from utils.data_and_files.file_utils import get_file_path\n",
    "\n",
    "class LMDBImageIterator(Iterator):\n",
    "\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_images,\n",
    "                 category,\n",
    "                 lmdb_dir,\n",
    "                 batch_size,\n",
    "                 episode_len=20,\n",
    "                 episode_shift=10,\n",
    "                 shuffle=True,\n",
    "                 seed=None,\n",
    "                 save_to_dir=None,\n",
    "                 save_prefix='',\n",
    "                 save_format='jpeg',\n",
    "                 dtype=K.floatx(),\n",
    "                 ):\n",
    "        \n",
    "        self.category = category\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        \n",
    "        self.lmdb_dir = lmdb_dir\n",
    "        self.episode_len = episode_len\n",
    "        self.episode_shift = episode_shift\n",
    "\n",
    "        \n",
    "        self.save_to_dir = save_to_dir\n",
    "        self.save_prefix = save_prefix\n",
    "        self.save_format = save_format\n",
    "        print(\"Initializing Iterator \" + category +\" Number of images \" +str(num_images))\n",
    "        print(category,lmdb_dir, batch_size,shuffle,seed)\n",
    "        self.env = lmdb.open(lmdb_dir, readonly=True)\n",
    "        \n",
    "        Iterator.__init__(self, num_images, batch_size, shuffle, seed)\n",
    "        \n",
    "        \n",
    "    def __del__(self):\n",
    "        self.env.close()\n",
    "        \n",
    "        \n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        print(index_array)\n",
    "        images, labels = [], []\n",
    "        \n",
    "        if len(index_array) < self.batch_size:\n",
    "            diff = self.batch_size//len(index_array) + 1\n",
    "            index_array = np.repeat(index_array, diff, axis=0)[:self.batch_size]\n",
    "\n",
    "        else:\n",
    "                with self.env.begin() as txn:\n",
    "                    for image_id in index_array:\n",
    "                        data = txn.get(f\"{image_id:08}\".encode(\"ascii\"))\n",
    "                        dataset = pickle.loads(data)\n",
    "                        images.append(dataset.get_image())\n",
    "                        labels_list = [attr for attr in dir(dataset) if not callable(getattr(dataset, attr)) and (not attr.startswith(\"__\")) and \n",
    "                           (not attr in ['image','channels',  'size'] )]\n",
    "\n",
    "                        for label in labels_list:\n",
    "                            _lab = {label: eval(f'dataset.{label}')}\n",
    "                            labels = {**labels, **_lab}\n",
    "        return {'images': images, **labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import hashlib\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from utils.data_and_files.data_utils import as_bytes\n",
    "from utils.reporting.logging import log_message\n",
    "\n",
    "\n",
    "class LMDBImageGenerator(ImageDataGenerator):\n",
    "    def flow_from_lmdb_lists(self, \n",
    "                              num_images,\n",
    "                              category,\n",
    "                              lmdb_dir,\n",
    "                              batch_size,\n",
    "                              episode_len=None,\n",
    "                              episode_shift=None,\n",
    "                              color_mode='rgb',\n",
    "                              shuffle =True,\n",
    "                              seed=None\n",
    "                              ):\n",
    "\n",
    "        \n",
    "          \n",
    "\n",
    "        return LMDBImageIterator(\n",
    "                             num_images = num_images,\n",
    "                             category = category,\n",
    "                             lmdb_dir = lmdb_dir,\n",
    "                             batch_size  = batch_size,\n",
    "                             episode_len = episode_len,\n",
    "                             episode_shift =episode_shift,\n",
    "                             shuffle = shuffle,\n",
    "                             seed = seed)\n",
    "\n",
    "\n",
    "def get_generators( val_lmdb_dir, val_num_images, tra_lmdb_dir, tra_num_images, \n",
    "                   batch_size, episode_len=None, episode_shift=None):\n",
    "\n",
    "    train_datagen = LMDBImageGenerator()\n",
    "\n",
    "    valid_datagen = LMDBImageGenerator()\n",
    "\n",
    "    train_generator = train_datagen.flow_from_lmdb_lists(\n",
    "        num_images = tra_num_images,\n",
    "        category='training',\n",
    "        lmdb_dir=tra_lmdb_dir,\n",
    "        batch_size=batch_size,\n",
    "        episode_len=episode_len,\n",
    "        episode_shift=episode_shift,\n",
    "        seed=0)\n",
    "\n",
    "    validation_generator = valid_datagen.flow_from_lmdb_lists(\n",
    "        num_images = val_num_images,\n",
    "        category='validation',\n",
    "        lmdb_dir=val_lmdb_dir,\n",
    "        batch_size=batch_size,\n",
    "        episode_len=episode_len,\n",
    "        episode_shift=episode_shift,\n",
    "        seed=0)\n",
    "\n",
    "    return train_generator, validation_generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator, testing_generator = get_generators(\n",
    "    val_lmdb_dir = '/home/azeghost/git/lmdb_new/LMDB_Datasets/.data/Pokemon_LMDB/_validation',\n",
    "    val_num_images = 218,\n",
    "    tra_lmdb_dir = '/home/azeghost/git/lmdb_new/LMDB_Datasets/.data/Pokemon_LMDB/_training', \n",
    "    tra_num_images = 591,\n",
    "    batch_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x, y = training_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Scale test for Pokemon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/azeghost/git/LMDB_Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper class for dataset\n",
    "class Pokemon_Image:\n",
    "    def __init__(self, image, label):\n",
    "        self.channels = image.shape[2]\n",
    "        self.size = image.shape[:2]\n",
    "        self.image = image.tobytes()\n",
    "        self.label = label #additional data to be stored (make it string)\n",
    "\n",
    "    def get_image(self):\n",
    "        \"\"\" Returns the image as a numpy array. \"\"\"\n",
    "        images = np.frombuffer(self.image, dtype=np.float32) #pay attention if you  don't use create_image_lists\n",
    "        return images.reshape(*self.size, self.channels)     #then dtype will be different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_single_lmdb(filename, img , index, label, num_images):\n",
    "    \"\"\" Stores a wrapper to LMDB.\n",
    "    \"\"\"\n",
    "    map_size = num_images * img.nbytes * 10\n",
    "    env = lmdb.open(filename, map_size=map_size)\n",
    "\n",
    "    # Same as before  but let's write all the images in a single transaction\n",
    "    with env.begin(write=True) as txn:\n",
    "          # All key-value pairs need to be Strings\n",
    "          value = Pokemon_Image(img, label)\n",
    "          key = f\"{index:08}\"\n",
    "          txn.put(key.encode(\"ascii\"), pickle.dumps(value))\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_lmdb(image_lists, image_dir, \n",
    "               lmdb_dir = '/content/LMDB',category='training', target_size=None,\n",
    "               color_mode='rgb', save_prefix='', save_format='png'):\n",
    "  classes = list(image_lists.keys())\n",
    "  num_class = len(classes)\n",
    "  class2id = dict(zip(classes, range(len(classes))))\n",
    "  id2class = dict((v, k) for k, v in class2id.items())\n",
    " \n",
    "  y = None\n",
    "  X = None\n",
    "\n",
    "  for label_name in classes:\n",
    "    num_images = len(image_lists[label_name][category])\n",
    "    print('Storing '+ str(num_images)+lmdb_dir+os.sep+'_{}'.format(category))\n",
    "    for index, _ in enumerate(image_lists[label_name][category]):\n",
    "        img_path = get_file_path(image_lists,\n",
    "                                  label_name,\n",
    "                                  index,\n",
    "                                  image_dir,\n",
    "                                  category)\n",
    "        img = img_to_array(\n",
    "                        load_img(\n",
    "                        img_path,\n",
    "                        grayscale=color_mode=='grayscale',\n",
    "                        target_size=target_size\n",
    "                        )\n",
    "                    )\n",
    "        name, _ = os.path.splitext(img_path)\n",
    "        vid_img_arr = name.split(sep=os.sep)[-1:]\n",
    "        y = [np.array(vid_img_arr)]     \n",
    "        name =  lmdb_dir+os.sep+'_{}'.format(category)\n",
    "        \n",
    "        store_single_lmdb(index = index, filename=name, img = img,label = y ,num_images = num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMDB_transformer:\n",
    "    def __init(image_lists**, )\n",
    "        create_img_list\n",
    "    \n",
    "    def transform_store():\n",
    "        store_lmdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./LMDB/\n",
    "!mkdir ./LMDB/\n",
    "# save_to_dir=None,\n",
    "store_lmdb(image_lists, image_dir=images_dir, lmdb_dir = './LMDB'\n",
    "           ,category='training',target_size=None,color_mode='rgb',save_prefix='',save_format='png')\n",
    "store_lmdb(image_lists, image_dir=images_dir, lmdb_dir = './LMDB'\n",
    "           ,category='validation',target_size=None,color_mode='rgb',save_prefix='',save_format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done on ubuntu system is local machine does not have tar \n",
    " - Install git bash then u can use such commands.\n",
    " - Go to windows store and download Ubuntu emulator wich just installs bash\n",
    " - On colab these should work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
