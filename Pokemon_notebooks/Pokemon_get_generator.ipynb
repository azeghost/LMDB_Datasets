{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up required packages and code from old repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Generative_Models'...\n",
      "remote: Enumerating objects: 2792, done.\u001b[K\n",
      "remote: Counting objects: 100% (2792/2792), done.\u001b[K\n",
      "remote: Compressing objects: 100% (782/782), done.\u001b[K\n",
      "remote: Total 15616 (delta 2024), reused 2584 (delta 1853), pack-reused 12824\u001b[K\n",
      "Receiving objects: 100% (15616/15616), 414.85 MiB | 16.89 MiB/s, done.\n",
      "Resolving deltas: 100% (10625/10625), done.\n",
      "Checking out files: 100% (1675/1675), done.\n",
      "error: pathspec 'lmdb' did not match any file(s) known to git.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/kkahloots/Generative_Models.git # this is for loading git with correct brach\n",
    "!cd  ./Generative_Models\n",
    "!git checkout lmdb\n",
    "!cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/azeghost/git/Generative_Models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/azeghost/git/LMDB_Datasets') # adress to git dir\n",
    "print(os.getcwd())\n",
    "from training.generators.file_image_generator import create_image_lists, get_generators\n",
    "import numpy as np\n",
    "import lmdb\n",
    "import pickle\n",
    "import sys\n",
    "from keras.preprocessing.image import Iterator, load_img, img_to_array, array_to_img\n",
    "from utils.data_and_files.file_utils import get_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store images in lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '/home/azeghost/git/Generative_Models/data/.pokemon/' #Folder to images\n",
    "validation_percentage = 30\n",
    "valid_format = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'DS06'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m809 file found\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_lists = create_image_lists(\n",
    "    image_dir=images_dir, \n",
    "    validation_pct=validation_percentage, \n",
    "    valid_imgae_formats=valid_format,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/azeghost/git/LMDB_Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper class for dataset\n",
    "class Pokemon_Image:\n",
    "    def __init__(self, image, label):\n",
    "        self.channels = image.shape[2]\n",
    "        self.size = image.shape[:2]\n",
    "        self.image = image.tobytes()\n",
    "        self.label = label #additional data to be stored (make it string)\n",
    "\n",
    "    def get_image(self):\n",
    "        \"\"\" Returns the image as a numpy array. \"\"\"\n",
    "        images = np.frombuffer(self.image, dtype=np.float32) #pay attention if you  don't use create_image_lists\n",
    "        return images.reshape(*self.size, self.channels)     #then dtype will be different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_single_lmdb(filename, img , index, label, num_images):\n",
    "    \"\"\" Stores a wrapper to LMDB.\n",
    "    \"\"\"\n",
    "    map_size = num_images * img.nbytes * 10\n",
    "    env = lmdb.open(filename, map_size=map_size)\n",
    "\n",
    "    # Same as before — but let's write all the images in a single transaction\n",
    "    with env.begin(write=True) as txn:\n",
    "          # All key-value pairs need to be Strings\n",
    "          value = Pokemon_Image(img, label)\n",
    "          key = f\"{index:08}\"\n",
    "          txn.put(key.encode(\"ascii\"), pickle.dumps(value))\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_lmdb(image_lists, image_dir, \n",
    "               lmdb_dir = '/content/LMDB',category='training', target_size=None,\n",
    "               color_mode='rgb', save_prefix='', save_format='png'):\n",
    "  classes = list(image_lists.keys())\n",
    "  num_class = len(classes)\n",
    "  class2id = dict(zip(classes, range(len(classes))))\n",
    "  id2class = dict((v, k) for k, v in class2id.items())\n",
    " \n",
    "  y = None\n",
    "  X = None\n",
    "\n",
    "  for label_name in classes:\n",
    "    num_images = len(image_lists[label_name][category])\n",
    "    print('Storing '+ str(num_images)+lmdb_dir+os.sep+'_{}'.format(category))\n",
    "    for index, _ in enumerate(image_lists[label_name][category]):\n",
    "        img_path = get_file_path(image_lists,\n",
    "                                  label_name,\n",
    "                                  index,\n",
    "                                  image_dir,\n",
    "                                  category)\n",
    "        img = img_to_array(\n",
    "                        load_img(\n",
    "                        img_path,\n",
    "                        grayscale=color_mode=='grayscale',\n",
    "                        target_size=target_size\n",
    "                        )\n",
    "                    )\n",
    "        name, _ = os.path.splitext(img_path)\n",
    "        vid_img_arr = name.split(sep=os.sep)[-1:]\n",
    "        y = [np.array(vid_img_arr)]     \n",
    "        name =  lmdb_dir+os.sep+'_{}'.format(category)\n",
    "        \n",
    "        store_single_lmdb(index = index, filename=name, img = img,label = y ,num_images = num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing 591./LMDB/_training\n",
      "Storing 218./LMDB/_validation\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./LMDB/\n",
    "!mkdir ./LMDB/\n",
    "# save_to_dir=None,\n",
    "store_lmdb(image_lists, image_dir=images_dir, lmdb_dir = './LMDB'\n",
    "           ,category='training',target_size=None,color_mode='rgb',save_prefix='',save_format='png')\n",
    "store_lmdb(image_lists, image_dir=images_dir, lmdb_dir = './LMDB'\n",
    "           ,category='validation',target_size=None,color_mode='rgb',save_prefix='',save_format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done on ubuntu system is local machine does not have tar \n",
    " - Install git bash then u can use such commands.\n",
    " - Go to windows store and download Ubuntu emulator wich just installs bash\n",
    " - On colab these should work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Removing leading `/' from member names\n",
      "/home/azeghost/git/Generative_Models/LMDB/_training/data.mdb\n",
      "/home/azeghost/git/Generative_Models/LMDB/_training/lock.mdb\n"
     ]
    }
   ],
   "source": [
    "!tar -cvjf pokemon_training.tar.bz2 /home/azeghost/git/Generative_Models/LMDB/_training/* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!split -b 10M pokemon_training.tar.bz2 \"pokemon_training.tar.part\"\n",
    "#split -b <max size> <name of zip or dir to zip/name> <split file name beginning>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 azeghost azeghost  10M Jul 13 21:43 pokemon_training.tar.partaa\r\n",
      "-rw-r--r-- 1 azeghost azeghost  10M Jul 13 21:43 pokemon_training.tar.partab\r\n",
      "-rw-r--r-- 1 azeghost azeghost  10M Jul 13 21:43 pokemon_training.tar.partac\r\n",
      "-rw-r--r-- 1 azeghost azeghost  10M Jul 13 21:43 pokemon_training.tar.partad\r\n",
      "-rw-r--r-- 1 azeghost azeghost 4.4M Jul 13 21:43 pokemon_training.tar.partae\r\n"
     ]
    }
   ],
   "source": [
    "#Check if they are created\n",
    "!ls -lh pokemon_training.tar.part*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/azeghost/git/LMDB_Datasets/pokemon’: File exists\n",
      "total 181820\n",
      "drwxr-xr-x 3 azeghost azeghost     4096 Jul 13 21:43 .\n",
      "drwxr-xr-x 9 azeghost azeghost     4096 Jul 13 21:43 ..\n",
      "drwxr-xr-x 3 azeghost azeghost     4096 Jul  1 22:44 home\n",
      "-rw-r--r-- 1 azeghost azeghost 46540659 Jul  1 22:40 pokemon_training.tar.bz2\n",
      "-rw-r--r-- 1 azeghost azeghost 10485760 Jul 13 21:43 pokemon_training.tar.partaa\n",
      "-rw-r--r-- 1 azeghost azeghost 10485760 Jul 13 21:43 pokemon_training.tar.partab\n",
      "-rw-r--r-- 1 azeghost azeghost 10485760 Jul 13 21:43 pokemon_training.tar.partac\n",
      "-rw-r--r-- 1 azeghost azeghost 10485760 Jul 13 21:43 pokemon_training.tar.partad\n",
      "-rw-r--r-- 1 azeghost azeghost  4597619 Jul 13 21:43 pokemon_training.tar.partae\n",
      "-rw-r--r-- 1 azeghost azeghost 46540659 Jul  1 22:41 pokemon_validation.tar.bz2\n",
      "-rw-r--r-- 1 azeghost azeghost 46540659 Jul  1 22:30 pokemon_validation.tar.partaa\n"
     ]
    }
   ],
   "source": [
    "#move to correct folder and push to git\n",
    "!mkdir /home/azeghost/git/LMDB_Datasets/pokemon\n",
    "!mv pokemon_training.tar.part* /home/azeghost/git/LMDB_Datasets/pokemon\n",
    "!ls -la /home/azeghost/git/LMDB_Datasets/pokemon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push to git\n",
    "# !cd /home/azeghost/git/LMDB_Datasets\n",
    "# !git add ../pokemon/*\n",
    "# # !git status\n",
    "# !git commit -m \"pokemon_training\"\n",
    "# !git push orign master # Check if you have ssh token enabled for bash use otherwise enter login and password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Removing leading `/' from member names\n",
      "/home/azeghost/git/Generative_Models/LMDB/_validation/data.mdb\n",
      "/home/azeghost/git/Generative_Models/LMDB/_validation/lock.mdb\n"
     ]
    }
   ],
   "source": [
    "!tar -cvjf pokemon_validation.tar.bz2 /home/azeghost/git/Generative_Models/LMDB/_validation/* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 azeghost azeghost 45M Jul 13 21:43 pokemon_validation.tar.partaa\r\n"
     ]
    }
   ],
   "source": [
    "!split -b 200M pokemon_training.tar.bz2 \"pokemon_validation.tar.part\"\n",
    "!ls -lh pokemon_validation.tar.part*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/azeghost/git/LMDB_Datasets/pokemon’: File exists\n",
      "home\t\t\t     pokemon_training.tar.partad\n",
      "pokemon_training.tar.bz2     pokemon_training.tar.partae\n",
      "pokemon_training.tar.partaa  pokemon_validation.tar.bz2\n",
      "pokemon_training.tar.partab  pokemon_validation.tar.partaa\n",
      "pokemon_training.tar.partac\n"
     ]
    }
   ],
   "source": [
    "!mkdir /home/azeghost/git/LMDB_Datasets/pokemon\n",
    "!mv pokemon_validation.tar.part* /home/azeghost/git/LMDB_Datasets/pokemon\n",
    "!ls /home/azeghost/git/LMDB_Datasets/pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd /home/azeghost/git/LMDB_Datasets\n",
    "# !git add pokemon/*\n",
    "# !git status\n",
    "# !git commit -m \"pokemon_validation\"\n",
    "# !git push orign master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After downloading from Git combine and unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 181820\r\n",
      "drwxr-xr-x 2 azeghost azeghost     4096 Jul  1 22:40 .\r\n",
      "drwxr-xr-x 6 azeghost azeghost     4096 Jul  1 22:31 ..\r\n",
      "-rw-r--r-- 1 azeghost azeghost 46540659 Jul  1 22:40 pokemon_training.tar.bz2\r\n",
      "-rw-r--r-- 1 azeghost azeghost 10485760 Jul  1 22:35 pokemon_training.tar.partaa\r\n",
      "-rw-r--r-- 1 azeghost azeghost 10485760 Jul  1 22:35 pokemon_training.tar.partab\r\n",
      "-rw-r--r-- 1 azeghost azeghost 10485760 Jul  1 22:35 pokemon_training.tar.partac\r\n",
      "-rw-r--r-- 1 azeghost azeghost 10485760 Jul  1 22:35 pokemon_training.tar.partad\r\n",
      "-rw-r--r-- 1 azeghost azeghost  4597619 Jul  1 22:35 pokemon_training.tar.partae\r\n",
      "-rw-r--r-- 1 azeghost azeghost 46540659 Jul  1 22:39 pokemon_validation.tar.bz2\r\n",
      "-rw-r--r-- 1 azeghost azeghost 46540659 Jul  1 22:30 pokemon_validation.tar.partaa\r\n"
     ]
    }
   ],
   "source": [
    "#pokemon_training\n",
    "!cat /home/azeghost/git/LMDB_Datasets/pokemon/pokemon_training.tar.part* >/home/azeghost/git/LMDB_Datasets/pokemon/pokemon_training.tar.bz2\n",
    "#!cat <split files put * at the end> > <final zip name>\n",
    "!ls -la /home/azeghost/git/LMDB_Datasets/pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 181816\r\n",
      "drwxr-xr-x 2 azeghost azeghost     4096 Jul  1 22:40 .\r\n",
      "drwxr-xr-x 6 azeghost azeghost     4096 Jul  1 22:31 ..\r\n",
      "-rw-r--r-- 1 azeghost azeghost 46540659 Jul  1 22:40 pokemon_training.tar.bz2\r\n",
      "-rw-r--r-- 1 azeghost azeghost 10485760 Jul  1 22:35 pokemon_training.tar.partaa\r\n",
      "-rw-r--r-- 1 azeghost azeghost 10485760 Jul  1 22:35 pokemon_training.tar.partab\r\n",
      "-rw-r--r-- 1 azeghost azeghost 10485760 Jul  1 22:35 pokemon_training.tar.partac\r\n",
      "-rw-r--r-- 1 azeghost azeghost 10485760 Jul  1 22:35 pokemon_training.tar.partad\r\n",
      "-rw-r--r-- 1 azeghost azeghost  4597619 Jul  1 22:35 pokemon_training.tar.partae\r\n",
      "-rw-r--r-- 1 azeghost azeghost 46540659 Jul  1 22:41 pokemon_validation.tar.bz2\r\n",
      "-rw-r--r-- 1 azeghost azeghost 46540659 Jul  1 22:30 pokemon_validation.tar.partaa\r\n"
     ]
    }
   ],
   "source": [
    "#pokemon_validation\n",
    "!cat /home/azeghost/git/LMDB_Datasets/pokemon/pokemon_validation.tar.part* >/home/azeghost/git/LMDB_Datasets/pokemon/pokemon_validation.tar.bz2\n",
    "!ls -la /home/azeghost/git/LMDB_Datasets/pokemon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 40\r\n",
      "drwxr-xr-x 7 azeghost azeghost 4096 Jul  1 22:49 .\r\n",
      "drwxr-xr-x 5 azeghost azeghost 4096 Jun 25 08:39 ..\r\n",
      "drwxr-xr-x 8 azeghost azeghost 4096 Jul  1 22:31 .git\r\n",
      "drwxr-xr-x 3 azeghost azeghost 4096 Jul  1 22:49 home\r\n",
      "drwxrwxr-x 3 azeghost azeghost 4096 Jul  1 22:32 .idea\r\n",
      "-rw-rw-r-- 1 azeghost azeghost 8376 Jul  1 22:24 LMDB_Write_and_Read_R01.ipynb\r\n",
      "drwxr-xr-x 3 azeghost azeghost 4096 Jul  1 22:44 pokemon\r\n",
      "drwxr-xr-x 3 azeghost azeghost 4096 Jul  1 22:49 Pokemon\r\n"
     ]
    }
   ],
   "source": [
    "!tar -xf /home/azeghost/git/LMDB_Datasets/pokemon/pokemon_validation.tar.bz2 -C /home/azeghost/git/LMDB_Datasets\n",
    "!ls -la /home/azeghost/git/LMDB_Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the lmdb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_many_lmdb(lmdb_dir, num_images):\n",
    "\n",
    "    images, labels = [], []\n",
    "    env = lmdb.open(lmdb_dir, readonly=True)\n",
    "\n",
    "    # Start a new read transaction\n",
    "    with env.begin() as txn:\n",
    "        # Read all images in one single transaction, with one lock\n",
    "        # We could split this up into multiple transactions if needed\n",
    "        for image_id in range(num_images):\n",
    "            data = txn.get(f\"{image_id:08}\".encode(\"ascii\"))\n",
    "            # Remember that it's a CIFAR_Image object \n",
    "            # that is stored as the value\n",
    "            pokemon_image = pickle.loads(data)\n",
    "            images.append(pokemon_image.get_image())\n",
    "            labels.append(pokemon_image.label)\n",
    "    env.close()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = read_many_lmdb('./LMDB/_validation', 218)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/azeghost/git/Generative_Models/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import hashlib\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from utils.data_and_files.data_utils import as_bytes\n",
    "from utils.reporting.logging import log_message\n",
    "# from training.generators.image_iterator import LMDBImageIterator\n",
    "\n",
    "\n",
    "class LMDBImageGenerator(ImageDataGenerator):\n",
    "    def flow_from_lmdb_lists(self, \n",
    "                              category,\n",
    "                              batch_size,\n",
    "                              episode_len=None,\n",
    "                              episode_shift=None,\n",
    "                              color_mode='rgb',\n",
    "                              class_mode=None,\n",
    "                              shuffle=True,\n",
    "                              seed=None,\n",
    "                              save_to_dir=None,\n",
    "                              save_prefix='',\n",
    "                              save_format='jpg'):\n",
    "\n",
    "        return LMDBImageIterator(self,\n",
    "                             category,\n",
    "                             class_mode=class_mode,\n",
    "                             data_format=self.data_format,\n",
    "                             batch_size=batch_size,\n",
    "                             episode_len=episode_len,\n",
    "                             episode_shift=episode_shift,\n",
    "                             shuffle=shuffle,\n",
    "                             seed=seed,\n",
    "                             save_to_dir=save_to_dir,\n",
    "                             save_prefix=save_prefix,\n",
    "                             save_format=save_format)\n",
    "\n",
    "\n",
    "def get_generators( lmdb_dir, batch_size, class_mode, episode_len=None, episode_shift=None, scaler=255.0):\n",
    "\n",
    "    train_datagen = LMDBImageGenerator(rescale=1. / scaler)\n",
    "\n",
    "    valid_datagen = LMDBImageGenerator(rescale=1. / scaler)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_lmdb_lists(\n",
    "        category='training',\n",
    "        lmdb_dir=lmdb_dir,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=class_mode,\n",
    "        episode_len=episode_len,\n",
    "        episode_shift=episode_shift,\n",
    "        seed=0)\n",
    "\n",
    "    validation_generator = valid_datagen.flow_from_lmdb_lists(\n",
    "        image_lists=images_list,\n",
    "        category='validation',\n",
    "        image_dir=image_dir,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=class_mode,\n",
    "        episode_len=episode_len,\n",
    "        episode_shift=episode_shift,\n",
    "        seed=0)\n",
    "\n",
    "    return train_generator, validation_generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import Iterator, load_img, img_to_array, array_to_img\n",
    "from keras import backend as K\n",
    "import logging\n",
    "from utils.reporting.logging import log_message\n",
    "from utils.data_and_files.file_utils import get_file_path\n",
    "\n",
    "class LMDBImageIterator(Iterator):\n",
    "    \"\"\"Iterator capable of reading images from a directory on disk.\n",
    "\n",
    "    # Arguments\n",
    "        image_lists: Dictionary of training images for each label.\n",
    "        image_data_generator: Instance of `ImageDataGenerator`\n",
    "            to use for random transformations and normalization.\n",
    "        target_size: tuple of integers, dimensions to resize input images to.\n",
    "        color_mode: One of `\"rgb\"`, `\"grayscale\"`. Color mode to read images.\n",
    "        classes: Optional list of strings, names of sudirectories\n",
    "            containing images from each class (e.g. `[\"dogs\", \"cats\"]`).\n",
    "            It will be computed automatically if not set.\n",
    "        class_mode: Mode for yielding the targets:\n",
    "            `\"binary\"`: binary targets (if there are only two classes),\n",
    "            `\"categorical\"`: categorical targets,\n",
    "            `\"sparse\"`: integer targets,\n",
    "            `None`: no targets get yielded (only input images are yielded).\n",
    "            `episode`: a sequence of images yielded (with time shift).\n",
    "            `func`: custom transformation gets the input images and the transformed.\n",
    "\n",
    "        batch_size: Integer, size of a batch.\n",
    "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "        seed: Random seed for data shuffling.\n",
    "        data_format: String, one of `channels_first`, `channels_last`.\n",
    "        save_to_dir: Optional directory where to save the pictures\n",
    "            being yielded, in a viewable format. This is useful\n",
    "            for visualizing the random transformations being\n",
    "            applied, for debugging purposes.\n",
    "        save_prefix: String prefix to use for saving sample\n",
    "            images (if `save_to_dir` is set).\n",
    "        save_format: Format to use for saving sample images\n",
    "            (if `save_to_dir` is set).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 category,\n",
    "                 lmdb_dir,\n",
    "                 class_mode='categorical',\n",
    "                 batch_size=32,\n",
    "                 episode_len=20,\n",
    "                 episode_shift=10,\n",
    "                 shuffle=True,\n",
    "                 seed=None,\n",
    "                 save_to_dir=None,\n",
    "                 save_prefix='',\n",
    "                 save_format='jpeg',\n",
    "                 dtype=K.floatx(),\n",
    "                 number_of_records = 10\n",
    "                 \n",
    "                 ):\n",
    "        \n",
    "        self.category = category\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        \n",
    "        self.lmdb_dir = lmdb_dir\n",
    "        self.episode_len = episode_len\n",
    "        self.episode_shift = episode_shift\n",
    "\n",
    "        \n",
    "        \n",
    "#         self.class2id = dict(zip(classes, range(len(classes))))\n",
    "#         self.id2class = dict((v, k) for k, v in self.class2id.items())\n",
    "#         self.classes = np.zeros((self.samples,), dtype='int32')\n",
    "\n",
    "\n",
    "\n",
    "        if (class_mode not in {'categorical', 'binary', 'sparse', 'episode', 'episode_flat', None}) and (not hasattr(class_mode, '__call__')):\n",
    "            raise ValueError('Invalid class_mode:', class_mode,\n",
    "                             '; expected one of \"categorical\", '\n",
    "                             '\"binary\", \"sparse\", \"episode\", or None.')\n",
    "        self.class_mode = class_mode\n",
    "        self.dtype = dtype\n",
    "        self.save_to_dir = save_to_dir\n",
    "        self.save_prefix = save_prefix\n",
    "        self.save_format = save_format\n",
    "\n",
    "        Iterator.__init__(self, self.samples, self.batch_size, shuffle, seed)\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        \"\"\"For python 2.x.\n",
    "\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # with self.lock:\n",
    "        #    index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "        # The transformation of images is not under thread lock\n",
    "        # so it can be done in parallel\n",
    "\n",
    "        if len(index_array) < self.batch_size:\n",
    "            diff = self.batch_size//len(index_array) + 1\n",
    "            index_array = np.repeat(index_array, diff, axis=0)[:self.batch_size]\n",
    "\n",
    "#         grayscale = self.color_mode == 'grayscale'\n",
    "        else:\n",
    "            batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n",
    "            # build batch of image data\n",
    "            \n",
    "            env = lmdb.open(lmdb_dir, readonly=True)\n",
    "            \n",
    "            for i, j in enumerate(index_array):\n",
    "                \n",
    "                images, labels = [], []\n",
    "                \n",
    "\n",
    "                # Start a new read transaction\n",
    "                with env.begin() as txn:\n",
    "                    # Read all images in one single transaction, with one lock\n",
    "                    # We could split this up into multiple transactions if needed\n",
    "                    for image_id in index_array:\n",
    "#                         data = txn.get(f\"{image_id:08}\".encode(\"ascii\"))\n",
    "                        data = txn.get(image_id)\n",
    "    \n",
    "                        pokemon_image = pickle.loads(data)\n",
    "                        images.append(pokemon_image.get_image())\n",
    "                        labels.append(pokemon_image.label)\n",
    "                env.close()\n",
    "                return images, labels\n",
    "                \n",
    "                x = self.image_data_generator.random_transform(x)\n",
    "                x = self.image_data_generator.standardize(x)\n",
    "                batch_x[i] = x\n",
    "\n",
    "#             # optionally save augmented images to disk for debugging purposes\n",
    "#             if self.save_to_dir:\n",
    "#                 for i, j in enumerate(index_array):\n",
    "#                     img = array_to_img(batch_x[i], self.data_format, scale=True)\n",
    "#                     fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n",
    "#                                                                       index=j,\n",
    "#                                                                       hash=np.random.randint(10000),\n",
    "#                                                                       format=self.save_format)\n",
    "#                     img.save(os.path.join(self.save_to_dir, fname))\n",
    "            # build batch of labels\n",
    "            if self.class_mode == 'sparse':\n",
    "                batch_y = self.classes[index_array]\n",
    "            elif self.class_mode == 'binary':\n",
    "                batch_y = self.classes[index_array].astype(K.floatx())\n",
    "            elif self.class_mode == 'categorical':\n",
    "                batch_y = np.zeros((len(batch_x), self.num_class),dtype=K.floatx())\n",
    "                for i, label in enumerate(self.classes[index_array]):\n",
    "                    batch_y[i, label] = 1.\n",
    "\n",
    "            elif self.class_mode is None:\n",
    "                return batch_x\n",
    "            else:\n",
    "                return batch_x, self.class_mode(batch_x)\n",
    "            return batch_x, batch_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get keys \n",
    "#create a random batch size key list\n",
    "# get records return numpy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
