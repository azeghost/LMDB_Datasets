{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "qShWCYhaWHQx",
    "outputId": "1f18dfea-da6e-4127-9ea7-9abbc32566df",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/kkahloots/Generative_Models.git # this is for loading git with correct brach\n",
    "# %cd /content/Generative_Models/\n",
    "# !git checkout lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpKbF1EVV7Nj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip -q install keras\n",
    "!pip -q install colorlog\n",
    "!pip -q install keras-radam\n",
    "!pip -q install lmdb\n",
    "!pip -q install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PmZXJ3CuV7Nw",
    "outputId": "28279cbb-6e45-4cf8-b0f6-646b8c552b64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/azeghost/git/Generative_Models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../../Generative_Models/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OiXeRLQ6V7Nz"
   },
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Du4xX-ROV7N0"
   },
   "outputs": [],
   "source": [
    "dataset_name='pokemon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1WFTkEWV7N4"
   },
   "outputs": [],
   "source": [
    "images_dir = './data/.pokemon/'\n",
    "validation_percentage = 30\n",
    "valid_format = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ToDH6SfQV7N6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from training.generators.file_image_generator import create_image_lists, get_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "8cPsCGyIXL1f",
    "outputId": "578be4dd-7d93-48e7-d540-597f170e4768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 28\r\n",
      "drwxrwxr-x 3 azeghost azeghost  4096 Jun 26 22:40 .\r\n",
      "drwxr-xr-x 6 azeghost azeghost  4096 Jun 26 22:40 ..\r\n",
      "drwxrwxr-x 2 azeghost azeghost 20480 Jun 26 22:40 DS06\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la ./data/.pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "H9r17PIDV7OA",
    "outputId": "448d58b6-6bab-49ac-80b9-cdc9e0ad0612"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'DS06'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m809 file found\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_lists = create_image_lists(\n",
    "    image_dir=images_dir, \n",
    "    validation_pct=validation_percentage, \n",
    "    valid_imgae_formats=valid_format,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyXmrZlvV7OC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lmdb\n",
    "import pickle\n",
    "import math\n",
    "from keras.preprocessing.image import Iterator, load_img, img_to_array, array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rczoyv-mV7OF"
   },
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import get_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6h_uAIfMf1O"
   },
   "outputs": [],
   "source": [
    "class Pokemon_Image:\n",
    "    def __init__(self, image, label):\n",
    "        # Dimensions of image for reconstruction - not really necessary \n",
    "        # for this dataset, but some datasets may include images of \n",
    "        # varying sizes\n",
    "        self.channels = image.shape[2]\n",
    "        self.size = image.shape[:2]\n",
    "\n",
    "        self.image = image.tobytes()\n",
    "        self.label = label\n",
    "    def get_image(self):\n",
    "        \"\"\" Returns the image as a numpy array. \"\"\"\n",
    "        images = np.frombuffer(self.image, dtype=np.float32)\n",
    "        return images.reshape(*self.size, self.channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qfKHdegukc5-"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def store_single_lmdb(filename, img , index, label, num_images):\n",
    "    \"\"\" Stores a wrapper to LMDB.\n",
    "    \"\"\"\n",
    "    map_size = num_images * img.nbytes * 10\n",
    "    env = lmdb.open(filename, map_size=map_size)\n",
    "\n",
    "    # Same as before â€” but let's write all the images in a single transaction\n",
    "    with env.begin(write=True) as txn:\n",
    "          # All key-value pairs need to be Strings\n",
    "          value = Pokemon_Image(img, label)\n",
    "          key = f\"{index:08}\"\n",
    "          txn.put(key.encode(\"ascii\"), pickle.dumps(value))\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4HzorHfpOwXM"
   },
   "source": [
    "Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FH24Hqz8OuR9"
   },
   "outputs": [],
   "source": [
    "\n",
    "def store_lmdb(image_lists, image_dir, \n",
    "               lmdb_dir = '/content/LMDB',category='training', target_size=None,\n",
    "               color_mode='rgb', save_prefix='', save_format='png'):\n",
    "  classes = list(image_lists.keys())\n",
    "  num_class = len(classes)\n",
    "  class2id = dict(zip(classes, range(len(classes))))\n",
    "  id2class = dict((v, k) for k, v in class2id.items())\n",
    " \n",
    "  y = None\n",
    "  X = None\n",
    "\n",
    "  for label_name in classes:\n",
    "    num_images = len(image_lists[label_name][category])\n",
    "    print('Storing '+ str(num_images)+lmdb_dir+os.sep+'_{}'.format(category))\n",
    "    for index, _ in enumerate(image_lists[label_name][category]):\n",
    "        img_path = get_file_path(image_lists,\n",
    "                                  label_name,\n",
    "                                  index,\n",
    "                                  image_dir,\n",
    "                                  category)\n",
    "        img = img_to_array(\n",
    "                        load_img(\n",
    "                        img_path,\n",
    "                        grayscale=color_mode=='grayscale',\n",
    "                        target_size=target_size\n",
    "                        )\n",
    "                    )\n",
    "        name, _ = os.path.splitext(img_path)\n",
    "        vid_img_arr = name.split(sep=os.sep)[-1:]\n",
    "        y = [np.array(vid_img_arr)]     \n",
    "        name =  lmdb_dir+os.sep+'_{}'.format(category)\n",
    "        \n",
    "        store_single_lmdb(index = index, filename=name, img = img,label = y ,num_images = num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSRi5L-FVtOi"
   },
   "outputs": [],
   "source": [
    "!rm -rf ./LMDB/\n",
    "!mkdir ./LMDB/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "OlqEQB6WJ1EN",
    "outputId": "7c366a92-86c2-47f8-e11d-94bfe8532515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing 591./LMDB/_training\n",
      "Storing 218./LMDB/_validation\n"
     ]
    }
   ],
   "source": [
    "# save_to_dir=None,\n",
    "store_lmdb(image_lists, image_dir=images_dir, lmdb_dir = './LMDB',category='training',target_size=None,color_mode='rgb',save_prefix='',save_format='png')\n",
    "store_lmdb(image_lists, image_dir=images_dir, lmdb_dir = './LMDB',category='validation',target_size=None,color_mode='rgb',save_prefix='',save_format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_6dRUcRgOYe-"
   },
   "outputs": [],
   "source": [
    "# In  case we want each label to be a key then\n",
    "\n",
    "def store_many_lmdb_labelaskey(filename, images, labels):\n",
    "    \"\"\" Stores an array of images to LMDB.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        images       images array, (N, 32, 32, 3) to be stored\n",
    "        labels       labels array, (N, 1) to be stored\n",
    "    \"\"\"\n",
    "    num_images = len(images)\n",
    "\n",
    "    map_size = num_images * images[0].nbytes * 10\n",
    "\n",
    "    # Create a new LMDB DB for all the images\n",
    "    #str(lmdb_dir / f\"{num_images}_lmdb\")\n",
    "    env = lmdb.open(filename, map_size=map_size)\n",
    "\n",
    "    # Same as before â€” but let's write all the images in a single transaction\n",
    "    with env.begin(write=True) as txn:\n",
    "        for i in range(num_images):\n",
    "            # All key-value pairs need to be Strings\n",
    "            value = Pokemon_Image(images[i], labels[i])\n",
    "            key = labels[i]\n",
    "            txn.put(key.encode(\"ascii\"), pickle.dumps(value))\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_many_lmdb(lmdb_dir, num_images):\n",
    "\n",
    "    images, labels = [], []\n",
    "    env = lmdb.open(lmdb_dir, readonly=True)\n",
    "\n",
    "    # Start a new read transaction\n",
    "    with env.begin() as txn:\n",
    "        # Read all images in one single transaction, with one lock\n",
    "        # We could split this up into multiple transactions if needed\n",
    "        for image_id in range(num_images):\n",
    "            data = txn.get(f\"{image_id:08}\".encode(\"ascii\"))\n",
    "            # Remember that it's a CIFAR_Image object \n",
    "            # that is stored as the value\n",
    "            pokemon_image = pickle.loads(data)\n",
    "            images.append(pokemon_image.get_image())\n",
    "            labels.append(pokemon_image.label)\n",
    "    env.close()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvyZA8VHVzgz"
   },
   "source": [
    "Test 2 Reading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = read_many_lmdb('./LMDB/_validation', 218)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218 218\n"
     ]
    }
   ],
   "source": [
    "print(len(x), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rNX5NIC1vmIc"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def read_many_lmdb_old(filename, num_images):\n",
    "    \"\"\" Reads image from LMDB.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        num_images   number of images to read\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        images      images array, (N, 32, 32, 3) to be stored\n",
    "        labels      associated meta data, int label (N, 1)\n",
    "    \"\"\"\n",
    "    images, labels = [], []\n",
    "    #str(lmdb_dir / f\"{num_images}_lmdb\")\n",
    "    for folder_indx in  range(math.ceil(num_images/200)):\n",
    "      env = lmdb.open(filename+os.sep+'_{}'.format(float(folder_indx+1)), readonly=True)\n",
    "      print(folder_indx)\n",
    "      # Start a new read transaction\n",
    "      with env.begin() as txn:\n",
    "          # Read all images in one single transaction, with one lock\n",
    "          # We could split this up into multiple transactions if needed\n",
    "          if num_images- folder_indx*200 >200:\n",
    "            max_index = 200 \n",
    "          else:\n",
    "            max_index = num_images - folder_indx*200\n",
    "          \n",
    "          for image_id in range(0,max_index):\n",
    "              data = txn.get(f\"{image_id:08}\".encode(\"ascii\"))\n",
    "              # Remember that it's a CIFAR_Image object \n",
    "              # that is stored as the value\n",
    "              pokemon_image = pickle.loads(data)\n",
    "              # Retrieve the relevant bits\n",
    "              images.append(pokemon_image.get_images())\n",
    "              labels.append(pokemon_image.label)\n",
    "      env.close()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Image Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_many_lmdb_x(lmdb_dir, images, labels):\n",
    "    num_images = len(images)\n",
    "\n",
    "    map_size = num_images * images[0].nbytes * 10\n",
    "\n",
    "    # Create a new LMDB DB for all the images\n",
    "    env = lmdb.open(lmdb_dir, map_size=map_size)\n",
    "\n",
    "    # Same as before â€” but let's write all the images in a single transaction\n",
    "    with env.begin(write=True) as txn:\n",
    "        for i in range(num_images):\n",
    "            # All key-value pairs need to be Strings\n",
    "            \n",
    "            value = images[i].tobytes()\n",
    "            \n",
    "            key = f\"{i:08}\"\n",
    "            txn.put(key.encode(\"ascii\"), pickle.dumps(value))\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_many_lmdb_x(lmdb_dir, num_images):\n",
    "\n",
    "    images, labels = [], []\n",
    "    env = lmdb.open(lmdb_dir, readonly=True)\n",
    "\n",
    "    # Start a new read transaction\n",
    "    with env.begin() as txn:\n",
    "        # Read all images in one single transaction, with one lock\n",
    "        # We could split this up into multiple transactions if needed\n",
    "        for image_id in range(num_images):\n",
    "            data = txn.get(f\"{image_id:08}\".encode(\"ascii\"))\n",
    "            # Remember that it's a CIFAR_Image object \n",
    "            # that is stored as the value\n",
    "            image = pickle.loads(data)\n",
    "            image = np.frombuffer(image, dtype=np.float32)\n",
    "            image = image.reshape((400,400,3))\n",
    "            # Retrieve the relevant bits\n",
    "            images.append(image)\n",
    "#             labels.append(cifar_image.label)\n",
    "    env.close()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_images(image_lists, image_dir, \n",
    "               lmdb_dir = '/content/LMDB',category='training', target_size=None,\n",
    "               color_mode='rgb', save_prefix='', save_format='png'):\n",
    "  classes = list(image_lists.keys())\n",
    "  num_class = len(classes)\n",
    "  class2id = dict(zip(classes, range(len(classes))))\n",
    "  id2class = dict((v, k) for k, v in class2id.items())\n",
    " \n",
    "  y = None\n",
    "  X = None\n",
    "\n",
    "  for label_name in classes:\n",
    "    num_images = len(image_lists[label_name][category])\n",
    "    print('Storing '+ str(num_images)+lmdb_dir+os.sep+'_{}'.format(category))\n",
    "    for index, _ in enumerate(image_lists[label_name][category]):\n",
    "        if index < 3:\n",
    "            img_path = get_file_path(image_lists,\n",
    "                                      label_name,\n",
    "                                      index,\n",
    "                                      image_dir,\n",
    "                                      category)\n",
    "            img = img_to_array(\n",
    "                            load_img(\n",
    "                            img_path,\n",
    "                            grayscale=color_mode=='grayscale',\n",
    "                            target_size=target_size\n",
    "                            )\n",
    "                        )\n",
    "            name, _ = os.path.splitext(img_path)\n",
    "            vid_img_arr = name.split(sep=os.sep)[-1:]\n",
    "\n",
    "            if (y is None):\n",
    "                  y = [np.array(vid_img_arr)]\n",
    "            else:\n",
    "                  y = np.append(y, [np.array(vid_img_arr)], 0)\n",
    "            if (X is None):\n",
    "                  X = [np.array(img)]\n",
    "            else:\n",
    "                  X = np.append(X, [img], 0)\n",
    "    return X ,y      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing 218./LMDB/_validation\n",
      "(3, 400, 400, 3) (3, 1)\n"
     ]
    }
   ],
   "source": [
    "x, y = get_images(image_lists, image_dir=images_dir, lmdb_dir = './LMDB'\n",
    "           ,category='validation',target_size=None,color_mode='rgb'\n",
    "           ,save_prefix='',save_format='png')\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "store_many_lmdb_x('test', x , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt,yt = read_many_lmdb_x('test', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]\n",
      "\n",
      "  [[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]\n",
      "\n",
      "  [[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]\n",
      "\n",
      "  [[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]\n",
      "\n",
      "  [[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]]\n",
      "\n",
      "\n",
      " [[[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]\n",
      "\n",
      "  [[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]\n",
      "\n",
      "  [[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]\n",
      "\n",
      "  [[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]\n",
      "\n",
      "  [[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]]\n",
      "\n",
      "\n",
      " [[[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]\n",
      "\n",
      "  [[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]\n",
      "\n",
      "  [[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]\n",
      "\n",
      "  [[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]\n",
      "\n",
      "  [[ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   ...\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]\n",
      "   [ True  True  True]]]]\n"
     ]
    }
   ],
   "source": [
    "print(x == xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pokemon_dataset.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
