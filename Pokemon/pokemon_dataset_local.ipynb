{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "qShWCYhaWHQx",
    "outputId": "1f18dfea-da6e-4127-9ea7-9abbc32566df",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/kkahloots/Generative_Models.git # this is for loading git with correct brach\n",
    "# %cd /content/Generative_Models/\n",
    "# !git checkout lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpKbF1EVV7Nj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip -q install keras\n",
    "!pip -q install colorlog\n",
    "!pip -q install keras-radam\n",
    "!pip -q install lmdb\n",
    "!pip -q install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PmZXJ3CuV7Nw",
    "outputId": "28279cbb-6e45-4cf8-b0f6-646b8c552b64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/azeghost/git/Generative_Models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../../Generative_Models/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OiXeRLQ6V7Nz"
   },
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Du4xX-ROV7N0"
   },
   "outputs": [],
   "source": [
    "dataset_name='pokemon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1WFTkEWV7N4"
   },
   "outputs": [],
   "source": [
    "images_dir = './data/.pokemon/'\n",
    "validation_percentage = 30\n",
    "valid_format = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ToDH6SfQV7N6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from training.generators.file_image_generator import create_image_lists, get_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "8cPsCGyIXL1f",
    "outputId": "578be4dd-7d93-48e7-d540-597f170e4768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 28\r\n",
      "drwxr-xr-x 3 azeghost azeghost  4096 Jun 25 06:40 .\r\n",
      "drwxr-xr-x 6 azeghost azeghost  4096 Jun 25 06:40 ..\r\n",
      "drwxr-xr-x 2 azeghost azeghost 20480 Jun 25 06:40 DS06\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la ./data/.pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "H9r17PIDV7OA",
    "outputId": "448d58b6-6bab-49ac-80b9-cdc9e0ad0612"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'DS06'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m809 file found\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_lists = create_image_lists(\n",
    "    image_dir=images_dir, \n",
    "    validation_pct=validation_percentage, \n",
    "    valid_imgae_formats=valid_format,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyXmrZlvV7OC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lmdb\n",
    "import pickle\n",
    "import math\n",
    "from keras.preprocessing.image import Iterator, load_img, img_to_array, array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rczoyv-mV7OF"
   },
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import get_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6h_uAIfMf1O"
   },
   "outputs": [],
   "source": [
    "class Pokemon_Image:\n",
    "    def __init__(self, image, label):\n",
    "        # Dimensions of image for reconstruction - not really necessary \n",
    "        # for this dataset, but some datasets may include images of \n",
    "        # varying sizes\n",
    "        self.channels = image.shape[2]\n",
    "        self.size = image.shape[:2]\n",
    "\n",
    "        self.image = image.tobytes()\n",
    "        self.label = label\n",
    "\n",
    "    def get_images(self):\n",
    "        \"\"\" Returns the image as a numpy array. \"\"\"\n",
    "        images = np.frombuffer(self.image, dtype=np.uint8)\n",
    "        return images.reshape(-1,*self.size, self.channels)\n",
    "\n",
    "    def get_dims(self):\n",
    "        return np.zeros((self.channels, int(self.size[0]), int(self.size[1])))\n",
    "    \n",
    "    def get_image(self):\n",
    "        \"\"\" Returns the image as a numpy array. \"\"\"\n",
    "        images = np.frombuffer(self.image, dtype=np.uint8)\n",
    "        return images.reshape((*self.size, self.channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qfKHdegukc5-"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def store_single_lmdb(filename, wrapper , index, num_images):\n",
    "    \"\"\" Stores a wrapper to LMDB.\n",
    "    \"\"\"\n",
    "\n",
    "    map_size = wrapper.get_dims().nbytes * num_images + sys.getsizeof(wrapper.label) * 2 * num_images\n",
    "    env = lmdb.open(filename, map_size=map_size, create= True)\n",
    "\n",
    "    # Same as before â€” but let's write all the images in a single transaction\n",
    "    with env.begin(write=True) as txn:\n",
    "          # All key-value pairs need to be Strings\n",
    "          value = wrapper\n",
    "          key = f\"{index:08}\"\n",
    "          txn.put(key.encode(\"ascii\"), pickle.dumps(value))\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4HzorHfpOwXM"
   },
   "source": [
    "Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FH24Hqz8OuR9"
   },
   "outputs": [],
   "source": [
    "\n",
    "def store_lmdb(image_lists, image_dir, \n",
    "               lmdb_dir = '/content/LMDB',category='training', target_size=None,\n",
    "               color_mode='rgb', save_prefix='', save_format='png'):\n",
    "  classes = list(image_lists.keys())\n",
    "  num_class = len(classes)\n",
    "  class2id = dict(zip(classes, range(len(classes))))\n",
    "  id2class = dict((v, k) for k, v in class2id.items())\n",
    " \n",
    "  y = None\n",
    "  X = None\n",
    "\n",
    "  for label_name in classes:\n",
    "    num_images = len(image_lists[label_name][category])\n",
    "    print('Storing '+ str(num_images)+lmdb_dir+os.sep+'_{}'.format(category))\n",
    "    for index, _ in enumerate(image_lists[label_name][category]):\n",
    "        img_path = get_file_path(image_lists,\n",
    "                                  label_name,\n",
    "                                  index,\n",
    "                                  image_dir,\n",
    "                                  category)\n",
    "        img = img_to_array(\n",
    "                        load_img(\n",
    "                        img_path,\n",
    "                        grayscale=color_mode=='grayscale',\n",
    "                        target_size=target_size\n",
    "                        )\n",
    "                    )\n",
    "        name, _ = os.path.splitext(img_path)\n",
    "        vid_img_arr = name.split(sep=os.sep)[-1:]\n",
    "        y = [np.array(vid_img_arr)]\n",
    "        X = np.array(img)\n",
    "        \n",
    "        \n",
    "        name =  lmdb_dir+os.sep+'_{}'.format(category)\n",
    "        pokemon_Image = Pokemon_Image(X, y)\n",
    "\n",
    "        store_single_lmdb(index = index, filename=name, wrapper = pokemon_Image, num_images = num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSRi5L-FVtOi"
   },
   "outputs": [],
   "source": [
    "!rm -rf ./LMDB/\n",
    "!mkdir ./LMDB/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "OlqEQB6WJ1EN",
    "outputId": "7c366a92-86c2-47f8-e11d-94bfe8532515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing 591./LMDB/_training\n",
      "Storing 218./LMDB/_validation\n"
     ]
    }
   ],
   "source": [
    "# save_to_dir=None,\n",
    "\n",
    "store_lmdb(image_lists, image_dir=images_dir, lmdb_dir = './LMDB',category='training',target_size=None,color_mode='rgb',save_prefix='',save_format='png')\n",
    "store_lmdb(image_lists, image_dir=images_dir, lmdb_dir = './LMDB',category='validation',target_size=None,color_mode='rgb',save_prefix='',save_format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_6dRUcRgOYe-"
   },
   "outputs": [],
   "source": [
    "# In  case we want each label to be a key then\n",
    "\n",
    "def store_many_lmdb_labelaskey(filename, images, labels):\n",
    "    \"\"\" Stores an array of images to LMDB.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        images       images array, (N, 32, 32, 3) to be stored\n",
    "        labels       labels array, (N, 1) to be stored\n",
    "    \"\"\"\n",
    "    num_images = len(images)\n",
    "\n",
    "    map_size = num_images * images[0].nbytes * 10\n",
    "\n",
    "    # Create a new LMDB DB for all the images\n",
    "    #str(lmdb_dir / f\"{num_images}_lmdb\")\n",
    "    env = lmdb.open(filename, map_size=map_size)\n",
    "\n",
    "    # Same as before â€” but let's write all the images in a single transaction\n",
    "    with env.begin(write=True) as txn:\n",
    "        for i in range(num_images):\n",
    "            # All key-value pairs need to be Strings\n",
    "            value = Pokemon_Image(images[i], labels[i])\n",
    "            key = labels[i]\n",
    "            txn.put(key.encode(\"ascii\"), pickle.dumps(value))\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Yis1ehVNHAO"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def read_many_lmdb_1(filename, num_images):\n",
    "    \"\"\" Reads image from LMDB.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        num_images   number of images to read\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        images      images array, (N, 32, 32, 3) to be stored\n",
    "        labels      associated meta data, int label (N, 1)\n",
    "    \"\"\"\n",
    "    images, labels = [], []\n",
    "    #str(lmdb_dir / f\"{num_images}_lmdb\")\n",
    "    for folder_indx in  range(math.ceil(num_images/200)):\n",
    "      env = lmdb.open(filename+os.sep+'_{}'.format(float(folder_indx+1)), readonly=True)\n",
    "      print(folder_indx)\n",
    "      # Start a new read transaction\n",
    "      with env.begin() as txn:\n",
    "          # Read all images in one single transaction, with one lock\n",
    "          # We could split this up into multiple transactions if needed\n",
    "          if num_images- folder_indx*200 >200:\n",
    "            max_index = 200 \n",
    "          else:\n",
    "            max_index = num_images - folder_indx*200\n",
    "          \n",
    "          for image_id in range(0,max_index):\n",
    "              data = txn.get(f\"{image_id:08}\".encode(\"ascii\"))\n",
    "              # Remember that it's a CIFAR_Image object \n",
    "              # that is stored as the value\n",
    "              pokemon_image = pickle.loads(data)\n",
    "              # Retrieve the relevant bits\n",
    "              images.append(pokemon_image.get_image())\n",
    "              labels.append(pokemon_image.label)\n",
    "      env.close()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_many_lmdb(lmdb_dir, num_images):\n",
    "    \"\"\" Reads image from LMDB.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        num_images   number of images to read\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        images      images array, (N, 32, 32, 3) to be stored\n",
    "        labels      associated meta data, int label (N, 1)\n",
    "    \"\"\"\n",
    "    images, labels = [], []\n",
    "    env = lmdb.open(lmdb_dir , readonly=True)\n",
    "\n",
    "    # Start a new read transaction\n",
    "    with env.begin() as txn:\n",
    "        # Read all images in one single transaction, with one lock\n",
    "        # We could split this up into multiple transactions if needed\n",
    "        for image_id in range(num_images):\n",
    "            data = txn.get(f\"{image_id:08}\".encode(\"ascii\"))\n",
    "            # Remember that it's a CIFAR_Image object \n",
    "            # that is stored as the value\n",
    "            pokemon_image = pickle.loads(data)\n",
    "            print(type(pokemon_image))\n",
    "            print(type(pokemon_image.image))\n",
    "            x = np.frombuffer(pokemon_image.image, dtype=np.uint8)\n",
    "            print(x.shape)\n",
    "            break\n",
    "            # Retrieve the relevant bits\n",
    "            images.append(pokemon_image.get_image())\n",
    "            labels.append(pokemon_image.label)\n",
    "    env.close()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvyZA8VHVzgz"
   },
   "source": [
    "Test 2 Reading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PnVO4LsJV1vZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Pokemon_Image'>\n",
      "<class 'bytes'>\n",
      "(1920000,)\n"
     ]
    }
   ],
   "source": [
    "X, y = read_many_lmdb('./LMDB/_training', 591)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yUDiMvlmV7OI"
   },
   "outputs": [],
   "source": [
    "def store_lmdb(\n",
    "             lmdb_name,\n",
    "             image_lists,\n",
    "             category, \n",
    "             image_dir,\n",
    "             target_size=None,\n",
    "             color_mode='rgb',\n",
    "             save_to_dir=None,\n",
    "             save_prefix='',\n",
    "             save_format='png'\n",
    "):\n",
    "\n",
    "    classes = list(image_lists.keys())\n",
    "    num_class = len(classes)\n",
    "\n",
    "    class2id = dict(zip(classes, range(len(classes))))\n",
    "    id2class = dict((v, k) for k, v in class2id.items())\n",
    "\n",
    "    if color_mode not in {'rgb', 'grayscale'}:\n",
    "        raise ValueError('Invalid color mode:', color_mode, '; expected \"rgb\" or \"grayscale\".')\n",
    "\n",
    "    lmdb_env = lmdb.open(lmdb_name)\n",
    "    # lmdb_db = lmdb_env.begin(write=True)\n",
    "    # print(classes)\n",
    "    with lmdb_env.begin(write=True) as lmdb_db:\n",
    "      for label_name in classes:\n",
    "          for j, _ in enumerate(image_lists[label_name][category]):\n",
    "              img_path = get_file_path(image_lists,\n",
    "                                        label_name,\n",
    "                                        j,\n",
    "                                        image_dir,\n",
    "                                        category)\n",
    "              img = img_to_array(\n",
    "                              load_img(\n",
    "                              img_path,\n",
    "                              grayscale=color_mode=='grayscale',\n",
    "                              target_size=target_size\n",
    "                              )\n",
    "\n",
    "                          )\n",
    "              \n",
    "              str_id.encode('ascii'), datum.SerializeToString()\n",
    "              X.tobytes()\n",
    "\n",
    "              \n",
    "              lmdb_db.put(label_name.encode(), img, append=True, overwrite=False)      \n",
    "    lmdb_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "mcCwKY2uV7OM",
    "outputId": "1a40fec8-1082-4de9-aef2-f3e89888483d"
   },
   "outputs": [],
   "source": [
    "store_lmdb(lmdb_name='pokemon2', image_lists=imgs_list, category='training', image_dir=images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psebCwrqV7OO"
   },
   "outputs": [],
   "source": [
    "lmdb_env = lmdb.open('pokemon2')\n",
    "with lmdb_env.begin() as lmdb_txn:\n",
    "    with lmdb_txn.cursor() as lmdb_cursor:\n",
    "        for key, value in lmdb_cursor:  \n",
    "           print (key)\n",
    "           print (value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cj3rJJBoV7OU"
   },
   "outputs": [],
   "source": [
    "keys = [key for key, _ in lmdb_db.cursor() ]\n",
    "values = [value for _, value in lmdb_db.cursor() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SXuxj38fnoX8"
   },
   "outputs": [],
   "source": [
    "print(np.fromstring(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7vkfj8WaqRr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lmdb\n",
    "\n",
    "def write_lmdb(filename):\n",
    "    print ('Write lmdb')\n",
    "\n",
    "    lmdb_env = lmdb.open(filename, map_size=int(1e9))\n",
    "\n",
    "    n_samples= 2\n",
    "    X= (255*np.random.rand(n_samples,3,4,3)).astype(np.uint8)\n",
    "    y= np.random.rand(n_samples).astype(np.float32)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        with lmdb_env.begin(write=True) as lmdb_txn:\n",
    "            lmdb_txn.put('X_'+str(i), X)\n",
    "            lmdb_txn.put('y_'+str(i), y)\n",
    "\n",
    "            print ('X:',X)\n",
    "            print ('y:',y)\n",
    "\n",
    "def read_lmdb(filename):\n",
    "    print ('Read lmdb')\n",
    "\n",
    "    lmdb_env = lmdb.open(filename)\n",
    "    lmdb_txn = lmdb_env.begin()\n",
    "    lmdb_cursor = lmdb_txn.cursor()\n",
    "\n",
    "    n_samples=0\n",
    "    with lmdb_env.begin() as lmdb_txn:\n",
    "        with lmdb_txn.cursor() as lmdb_cursor:\n",
    "            for key, value in lmdb_cursor:  \n",
    "                print (key)\n",
    "                if('X' in key):\n",
    "                    print (np.fromstring(value, dtype=np.uint8))\n",
    "                if('y' in key):\n",
    "                    print (np.fromstring(value, dtype=np.float32))\n",
    "\n",
    "                n_samples=n_samples+1\n",
    "\n",
    "    print ('n_samples',n_samples)\n",
    "\n",
    "write_lmdb('temp.db')\n",
    "read_lmdb('temp.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rNX5NIC1vmIc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P1EZzmRtgqLA"
   },
   "source": [
    "Implemented in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AYXHuiUagskh"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import hashlib\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from utils.data_and_files.data_utils import as_bytes\n",
    "from utils.reporting.logging import log_message\n",
    "from .image_iterator import ImageIterator\n",
    "\n",
    "\n",
    "class FileImageGenerator(ImageDataGenerator):\n",
    "    def flow_from_image_lists(self, image_lists,\n",
    "                              category,\n",
    "                              image_dir,\n",
    "                              target_size,\n",
    "                              batch_size,\n",
    "                              episode_len=None,\n",
    "                              episode_shift=None,\n",
    "                              color_mode='rgb',\n",
    "                              class_mode=None,\n",
    "                              shuffle=True,\n",
    "                              seed=None,\n",
    "                              save_to_dir=None,\n",
    "                              save_prefix='',\n",
    "                              save_format='jpg'):\n",
    "\n",
    "        return ImageIterator(image_lists, self,\n",
    "                             category,\n",
    "                             image_dir,\n",
    "                             target_size=target_size,\n",
    "                             color_mode=color_mode,\n",
    "                             class_mode=class_mode,\n",
    "                             data_format=self.data_format,\n",
    "                             batch_size=batch_size,\n",
    "                             episode_len=episode_len,\n",
    "                             episode_shift=episode_shift,\n",
    "                             shuffle=shuffle, seed=seed,\n",
    "                             save_to_dir=save_to_dir,\n",
    "                             save_prefix=save_prefix,\n",
    "                             save_format=save_format)\n",
    "\n",
    "\n",
    "def create_image_lists(image_dir, validation_pct, valid_imgae_formats, max_num_images_per_class=2**27-1, verbose = 1):\n",
    "    \"\"\"Builds a list of training images from the file system.\n",
    "\n",
    "    Analyzes the sub folders in the image directory, splits them into stable\n",
    "    training, testing, and validation sets, and returns a data structure\n",
    "    describing the lists of images for each label and their paths.\n",
    "\n",
    "    # Arguments\n",
    "        image_dir: string path to a folder containing subfolders of images.\n",
    "        validation_pct: integer percentage of images reserved for validation.\n",
    "\n",
    "    # Returns\n",
    "        dictionary of label subfolder, with images split into training\n",
    "        and validation sets within each label.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(image_dir):\n",
    "        raise ValueError(\"Image directory {} not found.\".format(image_dir))\n",
    "    image_lists = {}\n",
    "    sub_dirs = [x[0] for x in os.walk(image_dir)]\n",
    "\n",
    "    sub_dirs_without_root = sub_dirs[1:]  # first element is root directory\n",
    "    for sub_dir in sub_dirs_without_root:\n",
    "        file_list = []\n",
    "        dir_name = os.path.basename(sub_dir)\n",
    "        if dir_name == image_dir:\n",
    "            continue\n",
    "        if verbose == 1:\n",
    "            log_message(\"Looking for images in '{}'\".format(dir_name), logging.DEBUG)\n",
    "\n",
    "        if isinstance(valid_imgae_formats, str):\n",
    "            valid_imgae_formats = [valid_imgae_formats]\n",
    "\n",
    "        for extension in valid_imgae_formats:\n",
    "            file_glob = os.path.join(image_dir, dir_name, '*.' + extension)\n",
    "            file_list.extend(glob.glob(file_glob))\n",
    "        if not file_list:\n",
    "            msg = 'No files found'\n",
    "            if verbose == 1:\n",
    "                log_message(msg, logging.WARN)\n",
    "            warnings.warn(msg)\n",
    "            continue\n",
    "        else:\n",
    "            if verbose == 1:\n",
    "                log_message('{} file found'.format(len(file_list)), logging.INFO)\n",
    "        if len(file_list) < 20:\n",
    "            msg = 'Folder has less than 20 images, which may cause issues.'\n",
    "            if verbose == 1:\n",
    "                log_message(msg, logging.WARN)\n",
    "            warnings.warn(msg)\n",
    "        elif len(file_list) > max_num_images_per_class:\n",
    "            msg='WARNING: Folder {} has more than {} images. Some '\\\n",
    "                          'images will never be selected.' \\\n",
    "                          .format(dir_name, max_num_images_per_class)\n",
    "            log_message(msg, logging.WARN)\n",
    "            warnings.warn(msg)\n",
    "        label_name = re.sub(r'[^a-z0-9]+', ' ', dir_name.lower())\n",
    "        training_images = []\n",
    "        validation_images = []\n",
    "        for file_name in file_list:\n",
    "            base_name = os.path.basename(file_name)\n",
    "            # Get the hash of the file name and perform variant assignment.\n",
    "            hash_name = hashlib.sha1(as_bytes(base_name)).hexdigest()\n",
    "            hash_pct = ((int(hash_name, 16) % (max_num_images_per_class  + 1)) *\n",
    "                        (100.0 / max_num_images_per_class))\n",
    "            if hash_pct < validation_pct:\n",
    "                validation_images.append(base_name)\n",
    "            else:\n",
    "                training_images.append(base_name)\n",
    "        image_lists[label_name] = {\n",
    "            'dir': dir_name,\n",
    "            'training': training_images,\n",
    "            'validation': validation_images,\n",
    "        }\n",
    "    return image_lists\n",
    "\n",
    "def get_generators(images_list, image_dir, image_size, batch_size, class_mode, episode_len=None, episode_shift=None, scaler=255.0):\n",
    "\n",
    "    train_datagen = FileImageGenerator(rescale=1. / scaler)\n",
    "\n",
    "    valid_datagen = FileImageGenerator(rescale=1. / scaler)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_image_lists(\n",
    "        image_lists=images_list,\n",
    "        category='training',\n",
    "        image_dir=image_dir,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=class_mode,\n",
    "        episode_len=episode_len,\n",
    "        episode_shift=episode_shift,\n",
    "        seed=0)\n",
    "\n",
    "    validation_generator = valid_datagen.flow_from_image_lists(\n",
    "        image_lists=images_list,\n",
    "        category='validation',\n",
    "        image_dir=image_dir,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=class_mode,\n",
    "        episode_len=episode_len,\n",
    "        episode_shift=episode_shift,\n",
    "        seed=0)\n",
    "\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v2u-Z7HdgzcS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import Iterator, load_img, img_to_array, array_to_img\n",
    "from keras import backend as K\n",
    "import logging\n",
    "from utils.reporting.logging import log_message\n",
    "from utils.data_and_files.file_utils import get_file_path\n",
    "\n",
    "class ImageIterator(Iterator):\n",
    "    \"\"\"Iterator capable of reading images from a directory on disk.\n",
    "\n",
    "    # Arguments\n",
    "        image_lists: Dictionary of training images for each label.\n",
    "        image_data_generator: Instance of `ImageDataGenerator`\n",
    "            to use for random transformations and normalization.\n",
    "        target_size: tuple of integers, dimensions to resize input images to.\n",
    "        color_mode: One of `\"rgb\"`, `\"grayscale\"`. Color mode to read images.\n",
    "        classes: Optional list of strings, names of sudirectories\n",
    "            containing images from each class (e.g. `[\"dogs\", \"cats\"]`).\n",
    "            It will be computed automatically if not set.\n",
    "        class_mode: Mode for yielding the targets:\n",
    "            `\"binary\"`: binary targets (if there are only two classes),\n",
    "            `\"categorical\"`: categorical targets,\n",
    "            `\"sparse\"`: integer targets,\n",
    "            `None`: no targets get yielded (only input images are yielded).\n",
    "            `episode`: a sequence of images yielded (with time shift).\n",
    "            `func`: custom transformation gets the input images and the transformed.\n",
    "\n",
    "        batch_size: Integer, size of a batch.\n",
    "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "        seed: Random seed for data shuffling.\n",
    "        data_format: String, one of `channels_first`, `channels_last`.\n",
    "        save_to_dir: Optional directory where to save the pictures\n",
    "            being yielded, in a viewable format. This is useful\n",
    "            for visualizing the random transformations being\n",
    "            applied, for debugging purposes.\n",
    "        save_prefix: String prefix to use for saving sample\n",
    "            images (if `save_to_dir` is set).\n",
    "        save_format: Format to use for saving sample images\n",
    "            (if `save_to_dir` is set).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 image_lists,\n",
    "                 image_data_generator,\n",
    "                 category, image_dir,\n",
    "                 target_size=(256, 256, 3),\n",
    "                 color_mode='rgb',\n",
    "                 class_mode='categorical',\n",
    "                 batch_size=32,\n",
    "                 episode_len=20,\n",
    "                 episode_shift=10,\n",
    "                 shuffle=True,\n",
    "                 seed=None,\n",
    "                 data_format=None,\n",
    "                 save_to_dir=None,\n",
    "                 save_prefix='',\n",
    "                 save_format='jpeg',\n",
    "                 dtype=K.floatx()\n",
    "                 ):\n",
    "        if data_format is None:\n",
    "            data_format = K.image_data_format()\n",
    "\n",
    "        classes = list(image_lists.keys())\n",
    "        self.category = category\n",
    "        self.batch_size = batch_size\n",
    "        self.num_class = len(classes)\n",
    "        self.image_lists = image_lists\n",
    "        self.image_dir = image_dir\n",
    "        self.episode_len = episode_len\n",
    "        self.episode_shift = episode_shift\n",
    "\n",
    "        how_many_files = 0\n",
    "        for label_name in classes:\n",
    "            for _ in self.image_lists[label_name][category]:\n",
    "                how_many_files += 1\n",
    "\n",
    "        self.samples = how_many_files\n",
    "        self.class2id = dict(zip(classes, range(len(classes))))\n",
    "        self.id2class = dict((v, k) for k, v in self.class2id.items())\n",
    "        self.classes = np.zeros((self.samples,), dtype='int32')\n",
    "\n",
    "        self.image_data_generator = image_data_generator\n",
    "        self.target_size = tuple(target_size)\n",
    "        if color_mode not in {'rgb', 'grayscale'}:\n",
    "            raise ValueError('Invalid color mode:', color_mode,\n",
    "                             '; expected \"rgb\" or \"grayscale\".')\n",
    "        self.color_mode = color_mode\n",
    "        self.data_format = data_format\n",
    "        self.image_shape = self.target_size\n",
    "\n",
    "        if (class_mode not in {'categorical', 'binary', 'sparse', 'episode', 'episode_flat', None}) and (not hasattr(class_mode, '__call__')):\n",
    "            raise ValueError('Invalid class_mode:', class_mode,\n",
    "                             '; expected one of \"categorical\", '\n",
    "                             '\"binary\", \"sparse\", \"episode\", or None.')\n",
    "        self.class_mode = class_mode\n",
    "        self.dtype = dtype\n",
    "        self.save_to_dir = save_to_dir\n",
    "        self.save_prefix = save_prefix\n",
    "        self.save_format = save_format\n",
    "\n",
    "        i = 0\n",
    "        self.filenames = []\n",
    "        for label_name in classes:\n",
    "            for j, _ in enumerate(self.image_lists[label_name][category]):\n",
    "                self.classes[i] = self.class2id[label_name]\n",
    "                img_path = get_file_path(self.image_lists,\n",
    "                                          label_name,\n",
    "                                          j,\n",
    "                                          self.image_dir,\n",
    "                                          self.category)\n",
    "                self.filenames.append(img_path)\n",
    "                i += 1\n",
    "        log_message(\"Found {} {} files\".format(len(self.filenames), category), logging.INFO)\n",
    "        Iterator.__init__(self, self.samples, self.batch_size, shuffle, seed)\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        \"\"\"For python 2.x.\n",
    "\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # with self.lock:\n",
    "        #    index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "\n",
    "        # The transformation of images is not under thread lock\n",
    "        # so it can be done in parallel\n",
    "\n",
    "        if len(index_array) < self.batch_size:\n",
    "            diff = self.batch_size//len(index_array) + 1\n",
    "            index_array = np.repeat(index_array, diff, axis=0)[:self.batch_size]\n",
    "\n",
    "        grayscale = self.color_mode == 'grayscale'\n",
    "        if self.class_mode == 'episode':\n",
    "            batch_x = np.zeros((len(index_array), self.episode_len) + self.image_shape, dtype=self.dtype)\n",
    "            batch_gt = np.zeros((len(index_array), self.episode_len) + self.image_shape, dtype=self.dtype)\n",
    "\n",
    "            def get_filename(path):\n",
    "                folder, file = path.split(os.path.sep)[-2:]\n",
    "                file_name = file.split('.')[0]\n",
    "                return folder, int(file_name)\n",
    "\n",
    "\n",
    "            sorted_filenames = sorted(self.filenames, key=lambda f: get_filename(f))\n",
    "\n",
    "            max_ix = int(get_filename(sorted_filenames[-1])[1])\n",
    "            last_ix = max_ix - (self.episode_len + self.episode_shift)\n",
    "\n",
    "            # build batch of image data\n",
    "            for i, j in enumerate(index_array):\n",
    "                if j > last_ix:\n",
    "                    j = j - last_ix\n",
    "\n",
    "                imgs = []\n",
    "                for ix in range(j, j+self.episode_len):\n",
    "                    imgs += [\n",
    "                        self.image_data_generator.standardize(\n",
    "                            img_to_array(\n",
    "                                load_img(\n",
    "                                    sorted_filenames[ix],\n",
    "                                    grayscale=grayscale,\n",
    "                                    target_size=self.target_size\n",
    "                                ),\n",
    "                                data_format=self.data_format\n",
    "                            )\n",
    "                        )\n",
    "                    ]\n",
    "                imgs = np.array(imgs)\n",
    "                batch_x[i] = imgs\n",
    "\n",
    "                imgs = []\n",
    "                for ix in range(j+self.episode_shift, j+self.episode_len+self.episode_shift):\n",
    "                    imgs += [\n",
    "                        self.image_data_generator.standardize(\n",
    "                            img_to_array(\n",
    "                                load_img(\n",
    "                                    sorted_filenames[ix],\n",
    "                                    grayscale=grayscale,\n",
    "                                    target_size=self.target_size\n",
    "                                ),\n",
    "                                data_format=self.data_format\n",
    "                            )\n",
    "                        )\n",
    "                    ]\n",
    "\n",
    "                imgs = np.array(imgs)\n",
    "                batch_gt[i] = imgs\n",
    "            return batch_x, batch_gt\n",
    "\n",
    "        elif self.class_mode == 'episode_flat':\n",
    "            batch_x = np.zeros((len(index_array), self.episode_len) + self.image_shape, dtype=self.dtype)\n",
    "            batch_gt = np.zeros((len(index_array), self.episode_len) + self.image_shape, dtype=self.dtype)\n",
    "\n",
    "            def get_filename(path):\n",
    "                folder, file = path.split(os.path.sep)[-2:]\n",
    "                file_name = file.split('.')[0]\n",
    "                return folder, int(file_name)\n",
    "\n",
    "            sorted_filenames = sorted(self.filenames, key=lambda f: get_filename(f))\n",
    "\n",
    "            max_ix = int(get_filename(sorted_filenames[-1])[1])\n",
    "            last_ix = max_ix - (self.episode_len + self.episode_shift)\n",
    "\n",
    "            # build batch of image data\n",
    "            for i, j in enumerate(index_array):\n",
    "                if j > last_ix:\n",
    "                    j = j - last_ix\n",
    "\n",
    "                imgs = []\n",
    "                for ix in range(j, j + self.episode_len):\n",
    "                    imgs += [\n",
    "                        self.image_data_generator.standardize(\n",
    "                            img_to_array(\n",
    "                                load_img(\n",
    "                                    sorted_filenames[ix],\n",
    "                                    grayscale=grayscale,\n",
    "                                    target_size=self.target_size\n",
    "                                ),\n",
    "                                data_format=self.data_format\n",
    "                            )\n",
    "                        )\n",
    "                    ]\n",
    "                imgs = np.array(imgs)\n",
    "                batch_x[i] = imgs\n",
    "\n",
    "                imgs = []\n",
    "                for ix in range(j + self.episode_shift, j + self.episode_len + self.episode_shift):\n",
    "                    imgs += [\n",
    "                        self.image_data_generator.standardize(\n",
    "                            img_to_array(\n",
    "                                load_img(\n",
    "                                    sorted_filenames[ix],\n",
    "                                    grayscale=grayscale,\n",
    "                                    target_size=self.target_size\n",
    "                                ),\n",
    "                                data_format=self.data_format\n",
    "                            )\n",
    "                        )\n",
    "                    ]\n",
    "\n",
    "                imgs = np.array(imgs)\n",
    "                batch_gt[i] = imgs\n",
    "            return np.reshape(batch_x, (-1,)+self.image_shape ), np.reshape(batch_gt, (-1,)+self.image_shape)\n",
    "        else:\n",
    "            batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n",
    "            # build batch of image data\n",
    "            for i, j in enumerate(index_array):\n",
    "                img = load_img(self.filenames[j],\n",
    "                               grayscale=grayscale,\n",
    "                               target_size=self.target_size)\n",
    "                x = img_to_array(img, data_format=self.data_format)\n",
    "                x = self.image_data_generator.random_transform(x)\n",
    "                x = self.image_data_generator.standardize(x)\n",
    "                batch_x[i] = x\n",
    "\n",
    "            # optionally save augmented images to disk for debugging purposes\n",
    "            if self.save_to_dir:\n",
    "                for i, j in enumerate(index_array):\n",
    "                    img = array_to_img(batch_x[i], self.data_format, scale=True)\n",
    "                    fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n",
    "                                                                      index=j,\n",
    "                                                                      hash=np.random.randint(10000),\n",
    "                                                                      format=self.save_format)\n",
    "                    img.save(os.path.join(self.save_to_dir, fname))\n",
    "            # build batch of labels\n",
    "            if self.class_mode == 'sparse':\n",
    "                batch_y = self.classes[index_array]\n",
    "            elif self.class_mode == 'binary':\n",
    "                batch_y = self.classes[index_array].astype(K.floatx())\n",
    "            elif self.class_mode == 'categorical':\n",
    "                batch_y = np.zeros((len(batch_x), self.num_class),dtype=K.floatx())\n",
    "                for i, label in enumerate(self.classes[index_array]):\n",
    "                    batch_y[i, label] = 1.\n",
    "\n",
    "            elif self.class_mode is None:\n",
    "                return batch_x\n",
    "            else:\n",
    "                return batch_x, self.class_mode(batch_x)\n",
    "            return batch_x, batch_y\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pokemon_dataset.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
