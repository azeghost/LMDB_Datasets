{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "pokemon_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qShWCYhaWHQx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1f18dfea-da6e-4127-9ea7-9abbc32566df"
      },
      "source": [
        "!git clone https://github.com/kkahloots/Generative_Models.git # this is for loading git with correct brach\n",
        "%cd /content/Generative_Models/\n",
        "!git checkout lmdb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Generative_Models'...\n",
            "remote: Enumerating objects: 2077, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/2077)\u001b[K\rremote: Counting objects:   1% (21/2077)\u001b[K\rremote: Counting objects:   2% (42/2077)\u001b[K\rremote: Counting objects:   3% (63/2077)\u001b[K\rremote: Counting objects:   4% (84/2077)\u001b[K\rremote: Counting objects:   5% (104/2077)\u001b[K\rremote: Counting objects:   6% (125/2077)\u001b[K\rremote: Counting objects:   7% (146/2077)\u001b[K\rremote: Counting objects:   8% (167/2077)\u001b[K\rremote: Counting objects:   9% (187/2077)\u001b[K\rremote: Counting objects:  10% (208/2077)\u001b[K\rremote: Counting objects:  11% (229/2077)\u001b[K\rremote: Counting objects:  12% (250/2077)\u001b[K\rremote: Counting objects:  13% (271/2077)\u001b[K\rremote: Counting objects:  14% (291/2077)\u001b[K\rremote: Counting objects:  15% (312/2077)\u001b[K\rremote: Counting objects:  16% (333/2077)\u001b[K\rremote: Counting objects:  17% (354/2077)\u001b[K\rremote: Counting objects:  18% (374/2077)\u001b[K\rremote: Counting objects:  19% (395/2077)\u001b[K\rremote: Counting objects:  20% (416/2077)\u001b[K\rremote: Counting objects:  21% (437/2077)\u001b[K\rremote: Counting objects:  22% (457/2077)\u001b[K\rremote: Counting objects:  23% (478/2077)\u001b[K\rremote: Counting objects:  24% (499/2077)\u001b[K\rremote: Counting objects:  25% (520/2077)\u001b[K\rremote: Counting objects:  26% (541/2077)\u001b[K\rremote: Counting objects:  27% (561/2077)\u001b[K\rremote: Counting objects:  28% (582/2077)\u001b[K\rremote: Counting objects:  29% (603/2077)\u001b[K\rremote: Counting objects:  30% (624/2077)\u001b[K\rremote: Counting objects:  31% (644/2077)\u001b[K\rremote: Counting objects:  32% (665/2077)\u001b[K\rremote: Counting objects:  33% (686/2077)\u001b[K\rremote: Counting objects:  34% (707/2077)\u001b[K\rremote: Counting objects:  35% (727/2077)\u001b[K\rremote: Counting objects:  36% (748/2077)\u001b[K\rremote: Counting objects:  37% (769/2077)\u001b[K\rremote: Counting objects:  38% (790/2077)\u001b[K\rremote: Counting objects:  39% (811/2077)\u001b[K\rremote: Counting objects:  40% (831/2077)\u001b[K\rremote: Counting objects:  41% (852/2077)\u001b[K\rremote: Counting objects:  42% (873/2077)\u001b[K\rremote: Counting objects:  43% (894/2077)\u001b[K\rremote: Counting objects:  44% (914/2077)\u001b[K\rremote: Counting objects:  45% (935/2077)\u001b[K\rremote: Counting objects:  46% (956/2077)\u001b[K\rremote: Counting objects:  47% (977/2077)\u001b[K\rremote: Counting objects:  48% (997/2077)\u001b[K\rremote: Counting objects:  49% (1018/2077)\u001b[K\rremote: Counting objects:  50% (1039/2077)\u001b[K\rremote: Counting objects:  51% (1060/2077)\u001b[K\rremote: Counting objects:  52% (1081/2077)\u001b[K\rremote: Counting objects:  53% (1101/2077)\u001b[K\rremote: Counting objects:  54% (1122/2077)\u001b[K\rremote: Counting objects:  55% (1143/2077)\u001b[K\rremote: Counting objects:  56% (1164/2077)\u001b[K\rremote: Counting objects:  57% (1184/2077)\u001b[K\rremote: Counting objects:  58% (1205/2077)\u001b[K\rremote: Counting objects:  59% (1226/2077)\u001b[K\rremote: Counting objects:  60% (1247/2077)\u001b[K\rremote: Counting objects:  61% (1267/2077)\u001b[K\rremote: Counting objects:  62% (1288/2077)\u001b[K\rremote: Counting objects:  63% (1309/2077)\u001b[K\rremote: Counting objects:  64% (1330/2077)\u001b[K\rremote: Counting objects:  65% (1351/2077)\u001b[K\rremote: Counting objects:  66% (1371/2077)\u001b[K\rremote: Counting objects:  67% (1392/2077)\u001b[K\rremote: Counting objects:  68% (1413/2077)\u001b[K\rremote: Counting objects:  69% (1434/2077)\u001b[K\rremote: Counting objects:  70% (1454/2077)\u001b[K\rremote: Counting objects:  71% (1475/2077)\u001b[K\rremote: Counting objects:  72% (1496/2077)\u001b[K\rremote: Counting objects:  73% (1517/2077)\u001b[K\rremote: Counting objects:  74% (1537/2077)\u001b[K\rremote: Counting objects:  75% (1558/2077)\u001b[K\rremote: Counting objects:  76% (1579/2077)\u001b[K\rremote: Counting objects:  77% (1600/2077)\u001b[K\rremote: Counting objects:  78% (1621/2077)\u001b[K\rremote: Counting objects:  79% (1641/2077)\u001b[K\rremote: Counting objects:  80% (1662/2077)\u001b[K\rremote: Counting objects:  81% (1683/2077)\u001b[K\rremote: Counting objects:  82% (1704/2077)\u001b[K\rremote: Counting objects:  83% (1724/2077)\u001b[K\rremote: Counting objects:  84% (1745/2077)\u001b[K\rremote: Counting objects:  85% (1766/2077)\u001b[K\rremote: Counting objects:  86% (1787/2077)\u001b[K\rremote: Counting objects:  87% (1807/2077)\u001b[K\rremote: Counting objects:  88% (1828/2077)\u001b[K\rremote: Counting objects:  89% (1849/2077)\u001b[K\rremote: Counting objects:  90% (1870/2077)\u001b[K\rremote: Counting objects:  91% (1891/2077)\u001b[K\rremote: Counting objects:  92% (1911/2077)\u001b[K\rremote: Counting objects:  93% (1932/2077)\u001b[K\rremote: Counting objects:  94% (1953/2077)\u001b[K\rremote: Counting objects:  95% (1974/2077)\u001b[K\rremote: Counting objects:  96% (1994/2077)\u001b[K\rremote: Counting objects:  97% (2015/2077)\u001b[K\rremote: Counting objects:  98% (2036/2077)\u001b[K\rremote: Counting objects:  99% (2057/2077)\u001b[K\rremote: Counting objects: 100% (2077/2077)\u001b[K\rremote: Counting objects: 100% (2077/2077), done.\u001b[K\n",
            "remote: Compressing objects: 100% (592/592), done.\u001b[K\n",
            "remote: Total 14901 (delta 1504), reused 1906 (delta 1367), pack-reused 12824\u001b[K\n",
            "Receiving objects: 100% (14901/14901), 414.67 MiB | 35.49 MiB/s, done.\n",
            "Resolving deltas: 100% (10105/10105), done.\n",
            "Checking out files: 100% (1675/1675), done.\n",
            "/content/Generative_Models\n",
            "Already on 'lmdb'\n",
            "Your branch is up to date with 'origin/lmdb'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jpKbF1EVV7Nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip -q install keras\n",
        "!pip -q install colorlog\n",
        "!pip -q install keras-radam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmZXJ3CuV7Nw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28279cbb-6e45-4cf8-b0f6-646b8c552b64"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/Generative_Models/')\n",
        "print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Generative_Models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiXeRLQ6V7Nz",
        "colab_type": "text"
      },
      "source": [
        "# Dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du4xX-ROV7N0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_name='pokemon'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1WFTkEWV7N4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_dir = '/content/Generative_Models/data/.pokemon/'\n",
        "validation_percentage = 30\n",
        "valid_format = 'png'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ToDH6SfQV7N6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from training.generators.file_image_generator import create_image_lists, get_generators"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cPsCGyIXL1f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "578be4dd-7d93-48e7-d540-597f170e4768"
      },
      "source": [
        "!ls -la /content/Generative_Models/data/.pokemon"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 28\n",
            "drwxr-xr-x 3 root root  4096 Jun 19 17:03 .\n",
            "drwxr-xr-x 6 root root  4096 Jun 19 17:03 ..\n",
            "drwxr-xr-x 2 root root 20480 Jun 19 17:03 DS06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9r17PIDV7OA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "448d58b6-6bab-49ac-80b9-cdc9e0ad0612"
      },
      "source": [
        "image_lists = create_image_lists(\n",
        "    image_dir=images_dir, \n",
        "    validation_pct=validation_percentage, \n",
        "    valid_imgae_formats=valid_format,\n",
        "    verbose = 1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'DS06'\u001b[0m\n",
            "  \u001b[32mINFO    \u001b[0m | \u001b[32m809 file found\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xyXmrZlvV7OC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import lmdb\n",
        "import pickle\n",
        "import math\n",
        "from keras.preprocessing.image import Iterator, load_img, img_to_array, array_to_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rczoyv-mV7OF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils.data_and_files.file_utils import get_file_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6h_uAIfMf1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Pokemon_Image:\n",
        "    def __init__(self, image, label):\n",
        "        # Dimensions of image for reconstruction - not really necessary \n",
        "        # for this dataset, but some datasets may include images of \n",
        "        # varying sizes\n",
        "        self.channels = image.shape[2]\n",
        "        self.size = image.shape[:2]\n",
        "\n",
        "        self.image = image.tobytes()\n",
        "        self.label = label\n",
        "\n",
        "    def get_images(self):\n",
        "        \"\"\" Returns the image as a numpy array. \"\"\"\n",
        "        images = np.frombuffer(self.image, dtype=np.uint8)\n",
        "        return images.reshape(-1,*self.size, self.channels)\n",
        "\n",
        "    def get_image(self):\n",
        "        \"\"\" Returns the image as a numpy array. \"\"\"\n",
        "        images = np.frombuffer(self.image, dtype=np.uint8)\n",
        "        # print(images.shape)\n",
        "        return images.reshape(np.array(self.size, self.channels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YC7w15ZM_8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def store_many_lmdb(filename, images, labels):\n",
        "    \"\"\" Stores an array of images to LMDB.\n",
        "        Parameters:\n",
        "        ---------------\n",
        "        images       images array, (N, 32, 32, 3) to be stored\n",
        "        labels       labels array, (N, 1) to be stored\n",
        "    \"\"\"\n",
        "    num_images = len(images)\n",
        "\n",
        "    map_size = num_images * images[0].nbytes * 10\n",
        "\n",
        "    # Create a new LMDB DB for all the images\n",
        "    #str(lmdb_dir / f\"{num_images}_lmdb\")\n",
        "    env = lmdb.open(filename, map_size=map_size, create= True)\n",
        "\n",
        "    # Same as before — but let's write all the images in a single transaction\n",
        "    with env.begin(write=True) as txn:\n",
        "        for i in range(num_images):\n",
        "            # All key-value pairs need to be Strings\n",
        "            value = Pokemon_Image(images[i], labels[i])\n",
        "            key = f\"{i:08}\"\n",
        "            txn.put(key.encode(\"ascii\"), pickle.dumps(value))\n",
        "    env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfKHdegukc5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "def store_single_lmdb(filename, wrapper , index, num_images):\n",
        "    \"\"\" Stores a wrapper to LMDB.\n",
        "    \"\"\"\n",
        "\n",
        "    map_size = wrapper.get_image().nbytes * num_images + sys.getsizeof(wrapper.label) * 2 * num_images\n",
        "    env = lmdb.open(filename, map_size=map_size, create= True)\n",
        "\n",
        "    # Same as before — but let's write all the images in a single transaction\n",
        "    with env.begin(write=True) as txn:\n",
        "          # All key-value pairs need to be Strings\n",
        "          value = wrapper\n",
        "          key = f\"{index:08}\"\n",
        "          txn.put(key.encode(\"ascii\"), pickle.dumps(value))\n",
        "    env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HzorHfpOwXM",
        "colab_type": "text"
      },
      "source": [
        "Test 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSRi5L-FVtOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/LMDB/\n",
        "!mkdir /content/LMDB/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH24Hqz8OuR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lmdb_dir = '/content/LMDB'\n",
        "\n",
        "category='training'\n",
        "\n",
        "# print('num_class',num_class)\n",
        "image_dir=images_dir\n",
        "\n",
        "target_size=None\n",
        "color_mode='rgb'\n",
        "# save_to_dir=None,\n",
        "save_prefix=''\n",
        "save_format='png'\n",
        "\n",
        "def store_lmdb(image_lists, image_dir, \n",
        "               lmdb_dir = '/content/LMDB',category='training', target_size=None,\n",
        "               color_mode='rgb', save_prefix='', save_format='png'):\n",
        "  classes = list(image_lists.keys())\n",
        "  num_class = len(classes)\n",
        "  class2id = dict(zip(classes, range(len(classes))))\n",
        "  id2class = dict((v, k) for k, v in class2id.items())\n",
        " \n",
        "  y = None\n",
        "  X = None\n",
        "\n",
        "  for label_name in classes:\n",
        "    num_images = len(image_lists[label_name][category])\n",
        "    for index, _ in enumerate(image_lists[label_name][category]):\n",
        "        img_path = get_file_path(image_lists,\n",
        "                                  label_name,\n",
        "                                  index,\n",
        "                                  image_dir,\n",
        "                                  category)\n",
        "        img = img_to_array(\n",
        "                        load_img(\n",
        "                        img_path,\n",
        "                        grayscale=color_mode=='grayscale',\n",
        "                        target_size=target_size\n",
        "                        )\n",
        "                    )\n",
        "        name, _ = os.path.splitext(img_path)\n",
        "        vid_img_arr = name.split(sep=os.sep)[-1:]\n",
        "        y = [np.array(vid_img_arr)]\n",
        "        X = np.array(img)\n",
        "        # print(X.shape)\n",
        "        # print(X.shape[2])\n",
        "        # print(X.shape[:2])\n",
        "        \n",
        "        name =  lmdb_dir+os.sep+'_{}'.format(category)\n",
        "        pokemon_Image = Pokemon_Image(X, y)\n",
        "\n",
        "        store_single_lmdb(index = index, filename=name, wrapper = pokemon_Image, num_images = num_images)\n",
        "        \n",
        "\n",
        "        # if (y is None):\n",
        "        #       y = [np.array(vid_img_arr)]\n",
        "        # else:\n",
        "        #       y = np.append(y, [np.array(vid_img_arr)], 0)\n",
        "        # if (X is None):\n",
        "        #       X = [np.array(img)]\n",
        "        # else:\n",
        "        #       X = np.append(X, [img], 0)\n",
        "        # if (index+1) % 200 == 0 and index != 0:\n",
        "        #     print('Loaded {} 200 pictures'.format((index+1) / 200))\n",
        "        #     print('Saving images as LMDB file')\n",
        "        #     store_many_lmdb(lmdb_dir+os.sep+'_{}'.format((index+1) / 200), images = X, labels = y)\n",
        "        #     y = None\n",
        "        #     X = None\n",
        "        # elif len(image_lists[label_name][category])-1 == index:\n",
        "        #     print('Loaded last {} pictures'.format(math.ceil((index+1) / 200)))\n",
        "        #     print('Saving images as LMDB file')\n",
        "        #     store_many_lmdb(lmdb_dir+os.sep+'_{}'.format(float(math.ceil((index+1) / 200))), images = X, labels = y)\n",
        "        #     y = None\n",
        "        #     X = None\n",
        "            \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlqEQB6WJ1EN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "7c366a92-86c2-47f8-e11d-94bfe8532515"
      },
      "source": [
        "store_lmdb(image_lists, image_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-141-c97d5feaaf7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstore_lmdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_lists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-140-d2eae680df68>\u001b[0m in \u001b[0;36mstore_lmdb\u001b[0;34m(image_lists, image_dir, lmdb_dir, category, target_size, color_mode, save_prefix, save_format)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mpokemon_Image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPokemon_Image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mstore_single_lmdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpokemon_Image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-135-2c1acc1b1977>\u001b[0m in \u001b[0;36mstore_single_lmdb\u001b[0;34m(filename, wrapper, index, num_images)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmap_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_images\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlmdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-133-08415c2a3642>\u001b[0m in \u001b[0;36mget_image\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# print(images.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'tuple' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6dRUcRgOYe-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In  case we want each label to be a key then\n",
        "\n",
        "def store_many_lmdb_labelaskey(filename, images, labels):\n",
        "    \"\"\" Stores an array of images to LMDB.\n",
        "        Parameters:\n",
        "        ---------------\n",
        "        images       images array, (N, 32, 32, 3) to be stored\n",
        "        labels       labels array, (N, 1) to be stored\n",
        "    \"\"\"\n",
        "    num_images = len(images)\n",
        "\n",
        "    map_size = num_images * images[0].nbytes * 10\n",
        "\n",
        "    # Create a new LMDB DB for all the images\n",
        "    #str(lmdb_dir / f\"{num_images}_lmdb\")\n",
        "    env = lmdb.open(filename, map_size=map_size)\n",
        "\n",
        "    # Same as before — but let's write all the images in a single transaction\n",
        "    with env.begin(write=True) as txn:\n",
        "        for i in range(num_images):\n",
        "            # All key-value pairs need to be Strings\n",
        "            value = Pokemon_Image(images[i], labels[i])\n",
        "            key = labels[i]\n",
        "            txn.put(key.encode(\"ascii\"), pickle.dumps(value))\n",
        "    env.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcnCHtsakZd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yis1ehVNHAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def read_many_lmdb(filename, num_images):\n",
        "    \"\"\" Reads image from LMDB.\n",
        "        Parameters:\n",
        "        ---------------\n",
        "        num_images   number of images to read\n",
        "\n",
        "        Returns:\n",
        "        ----------\n",
        "        images      images array, (N, 32, 32, 3) to be stored\n",
        "        labels      associated meta data, int label (N, 1)\n",
        "    \"\"\"\n",
        "    images, labels = [], []\n",
        "    #str(lmdb_dir / f\"{num_images}_lmdb\")\n",
        "    for folder_indx in  range(math.ceil(num_images/200)):\n",
        "      env = lmdb.open(filename+os.sep+'_{}'.format(float(folder_indx+1)), readonly=True)\n",
        "      print(folder_indx)\n",
        "      # Start a new read transaction\n",
        "      with env.begin() as txn:\n",
        "          # Read all images in one single transaction, with one lock\n",
        "          # We could split this up into multiple transactions if needed\n",
        "          if num_images- folder_indx*200 >200:\n",
        "            max_index = 200 \n",
        "          else:\n",
        "            max_index = num_images - folder_indx*200\n",
        "          \n",
        "          for image_id in range(0,max_index):\n",
        "              data = txn.get(f\"{image_id:08}\".encode(\"ascii\"))\n",
        "              # Remember that it's a CIFAR_Image object \n",
        "              # that is stored as the value\n",
        "              pokemon_image = pickle.loads(data)\n",
        "              # Retrieve the relevant bits\n",
        "              images.append(pokemon_image.get_images())\n",
        "              labels.append(pokemon_image.label)\n",
        "      env.close()\n",
        "    return images, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvyZA8VHVzgz",
        "colab_type": "text"
      },
      "source": [
        "Test 2 Reading data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnVO4LsJV1vZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = read_many_lmdb(lmdb_dir, 809)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzHlQeEku3Jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUDiMvlmV7OI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def store_lmdb(\n",
        "             lmdb_name,\n",
        "             image_lists,\n",
        "             category, \n",
        "             image_dir,\n",
        "             target_size=None,\n",
        "             color_mode='rgb',\n",
        "             save_to_dir=None,\n",
        "             save_prefix='',\n",
        "             save_format='png'\n",
        "):\n",
        "\n",
        "    classes = list(image_lists.keys())\n",
        "    num_class = len(classes)\n",
        "\n",
        "    class2id = dict(zip(classes, range(len(classes))))\n",
        "    id2class = dict((v, k) for k, v in class2id.items())\n",
        "\n",
        "    if color_mode not in {'rgb', 'grayscale'}:\n",
        "        raise ValueError('Invalid color mode:', color_mode, '; expected \"rgb\" or \"grayscale\".')\n",
        "\n",
        "    lmdb_env = lmdb.open(lmdb_name)\n",
        "    # lmdb_db = lmdb_env.begin(write=True)\n",
        "    # print(classes)\n",
        "    with lmdb_env.begin(write=True) as lmdb_db:\n",
        "      for label_name in classes:\n",
        "          for j, _ in enumerate(image_lists[label_name][category]):\n",
        "              img_path = get_file_path(image_lists,\n",
        "                                        label_name,\n",
        "                                        j,\n",
        "                                        image_dir,\n",
        "                                        category)\n",
        "              img = img_to_array(\n",
        "                              load_img(\n",
        "                              img_path,\n",
        "                              grayscale=color_mode=='grayscale',\n",
        "                              target_size=target_size\n",
        "                              )\n",
        "\n",
        "                          )\n",
        "              \n",
        "              str_id.encode('ascii'), datum.SerializeToString()\n",
        "              X.tobytes()\n",
        "\n",
        "              \n",
        "              lmdb_db.put(label_name.encode(), img, append=True, overwrite=False)      \n",
        "    lmdb_env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcCwKY2uV7OM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "1a40fec8-1082-4de9-aef2-f3e89888483d"
      },
      "source": [
        "store_lmdb(lmdb_name='pokemon2', image_lists=imgs_list, category='training', image_dir=images_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-10ec2bc5e165>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstore_lmdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmdb_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pokemon2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_lists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimgs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'imgs_list' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psebCwrqV7OO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lmdb_env = lmdb.open('pokemon2')\n",
        "with lmdb_env.begin() as lmdb_txn:\n",
        "    with lmdb_txn.cursor() as lmdb_cursor:\n",
        "        for key, value in lmdb_cursor:  \n",
        "           print (key)\n",
        "           print (value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj3rJJBoV7OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keys = [key for key, _ in lmdb_db.cursor() ]\n",
        "values = [value for _, value in lmdb_db.cursor() ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXuxj38fnoX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.fromstring(values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7vkfj8WaqRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import lmdb\n",
        "\n",
        "def write_lmdb(filename):\n",
        "    print ('Write lmdb')\n",
        "\n",
        "    lmdb_env = lmdb.open(filename, map_size=int(1e9))\n",
        "\n",
        "    n_samples= 2\n",
        "    X= (255*np.random.rand(n_samples,3,4,3)).astype(np.uint8)\n",
        "    y= np.random.rand(n_samples).astype(np.float32)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        with lmdb_env.begin(write=True) as lmdb_txn:\n",
        "            lmdb_txn.put('X_'+str(i), X)\n",
        "            lmdb_txn.put('y_'+str(i), y)\n",
        "\n",
        "            print ('X:',X)\n",
        "            print ('y:',y)\n",
        "\n",
        "def read_lmdb(filename):\n",
        "    print ('Read lmdb')\n",
        "\n",
        "    lmdb_env = lmdb.open(filename)\n",
        "    lmdb_txn = lmdb_env.begin()\n",
        "    lmdb_cursor = lmdb_txn.cursor()\n",
        "\n",
        "    n_samples=0\n",
        "    with lmdb_env.begin() as lmdb_txn:\n",
        "        with lmdb_txn.cursor() as lmdb_cursor:\n",
        "            for key, value in lmdb_cursor:  \n",
        "                print (key)\n",
        "                if('X' in key):\n",
        "                    print (np.fromstring(value, dtype=np.uint8))\n",
        "                if('y' in key):\n",
        "                    print (np.fromstring(value, dtype=np.float32))\n",
        "\n",
        "                n_samples=n_samples+1\n",
        "\n",
        "    print ('n_samples',n_samples)\n",
        "\n",
        "write_lmdb('temp.db')\n",
        "read_lmdb('temp.db')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNX5NIC1vmIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1EZzmRtgqLA",
        "colab_type": "text"
      },
      "source": [
        "Implemented in code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYXHuiUagskh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import hashlib\n",
        "import logging\n",
        "import os\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from utils.data_and_files.data_utils import as_bytes\n",
        "from utils.reporting.logging import log_message\n",
        "from .image_iterator import ImageIterator\n",
        "\n",
        "\n",
        "class FileImageGenerator(ImageDataGenerator):\n",
        "    def flow_from_image_lists(self, image_lists,\n",
        "                              category,\n",
        "                              image_dir,\n",
        "                              target_size,\n",
        "                              batch_size,\n",
        "                              episode_len=None,\n",
        "                              episode_shift=None,\n",
        "                              color_mode='rgb',\n",
        "                              class_mode=None,\n",
        "                              shuffle=True,\n",
        "                              seed=None,\n",
        "                              save_to_dir=None,\n",
        "                              save_prefix='',\n",
        "                              save_format='jpg'):\n",
        "\n",
        "        return ImageIterator(image_lists, self,\n",
        "                             category,\n",
        "                             image_dir,\n",
        "                             target_size=target_size,\n",
        "                             color_mode=color_mode,\n",
        "                             class_mode=class_mode,\n",
        "                             data_format=self.data_format,\n",
        "                             batch_size=batch_size,\n",
        "                             episode_len=episode_len,\n",
        "                             episode_shift=episode_shift,\n",
        "                             shuffle=shuffle, seed=seed,\n",
        "                             save_to_dir=save_to_dir,\n",
        "                             save_prefix=save_prefix,\n",
        "                             save_format=save_format)\n",
        "\n",
        "\n",
        "def create_image_lists(image_dir, validation_pct, valid_imgae_formats, max_num_images_per_class=2**27-1, verbose = 1):\n",
        "    \"\"\"Builds a list of training images from the file system.\n",
        "\n",
        "    Analyzes the sub folders in the image directory, splits them into stable\n",
        "    training, testing, and validation sets, and returns a data structure\n",
        "    describing the lists of images for each label and their paths.\n",
        "\n",
        "    # Arguments\n",
        "        image_dir: string path to a folder containing subfolders of images.\n",
        "        validation_pct: integer percentage of images reserved for validation.\n",
        "\n",
        "    # Returns\n",
        "        dictionary of label subfolder, with images split into training\n",
        "        and validation sets within each label.\n",
        "    \"\"\"\n",
        "    if not os.path.isdir(image_dir):\n",
        "        raise ValueError(\"Image directory {} not found.\".format(image_dir))\n",
        "    image_lists = {}\n",
        "    sub_dirs = [x[0] for x in os.walk(image_dir)]\n",
        "\n",
        "    sub_dirs_without_root = sub_dirs[1:]  # first element is root directory\n",
        "    for sub_dir in sub_dirs_without_root:\n",
        "        file_list = []\n",
        "        dir_name = os.path.basename(sub_dir)\n",
        "        if dir_name == image_dir:\n",
        "            continue\n",
        "        if verbose == 1:\n",
        "            log_message(\"Looking for images in '{}'\".format(dir_name), logging.DEBUG)\n",
        "\n",
        "        if isinstance(valid_imgae_formats, str):\n",
        "            valid_imgae_formats = [valid_imgae_formats]\n",
        "\n",
        "        for extension in valid_imgae_formats:\n",
        "            file_glob = os.path.join(image_dir, dir_name, '*.' + extension)\n",
        "            file_list.extend(glob.glob(file_glob))\n",
        "        if not file_list:\n",
        "            msg = 'No files found'\n",
        "            if verbose == 1:\n",
        "                log_message(msg, logging.WARN)\n",
        "            warnings.warn(msg)\n",
        "            continue\n",
        "        else:\n",
        "            if verbose == 1:\n",
        "                log_message('{} file found'.format(len(file_list)), logging.INFO)\n",
        "        if len(file_list) < 20:\n",
        "            msg = 'Folder has less than 20 images, which may cause issues.'\n",
        "            if verbose == 1:\n",
        "                log_message(msg, logging.WARN)\n",
        "            warnings.warn(msg)\n",
        "        elif len(file_list) > max_num_images_per_class:\n",
        "            msg='WARNING: Folder {} has more than {} images. Some '\\\n",
        "                          'images will never be selected.' \\\n",
        "                          .format(dir_name, max_num_images_per_class)\n",
        "            log_message(msg, logging.WARN)\n",
        "            warnings.warn(msg)\n",
        "        label_name = re.sub(r'[^a-z0-9]+', ' ', dir_name.lower())\n",
        "        training_images = []\n",
        "        validation_images = []\n",
        "        for file_name in file_list:\n",
        "            base_name = os.path.basename(file_name)\n",
        "            # Get the hash of the file name and perform variant assignment.\n",
        "            hash_name = hashlib.sha1(as_bytes(base_name)).hexdigest()\n",
        "            hash_pct = ((int(hash_name, 16) % (max_num_images_per_class  + 1)) *\n",
        "                        (100.0 / max_num_images_per_class))\n",
        "            if hash_pct < validation_pct:\n",
        "                validation_images.append(base_name)\n",
        "            else:\n",
        "                training_images.append(base_name)\n",
        "        image_lists[label_name] = {\n",
        "            'dir': dir_name,\n",
        "            'training': training_images,\n",
        "            'validation': validation_images,\n",
        "        }\n",
        "    return image_lists\n",
        "\n",
        "def get_generators(images_list, image_dir, image_size, batch_size, class_mode, episode_len=None, episode_shift=None, scaler=255.0):\n",
        "\n",
        "    train_datagen = FileImageGenerator(rescale=1. / scaler)\n",
        "\n",
        "    valid_datagen = FileImageGenerator(rescale=1. / scaler)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_image_lists(\n",
        "        image_lists=images_list,\n",
        "        category='training',\n",
        "        image_dir=image_dir,\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=class_mode,\n",
        "        episode_len=episode_len,\n",
        "        episode_shift=episode_shift,\n",
        "        seed=0)\n",
        "\n",
        "    validation_generator = valid_datagen.flow_from_image_lists(\n",
        "        image_lists=images_list,\n",
        "        category='validation',\n",
        "        image_dir=image_dir,\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=class_mode,\n",
        "        episode_len=episode_len,\n",
        "        episode_shift=episode_shift,\n",
        "        seed=0)\n",
        "\n",
        "    return train_generator, validation_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2u-Z7HdgzcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import Iterator, load_img, img_to_array, array_to_img\n",
        "from keras import backend as K\n",
        "import logging\n",
        "from utils.reporting.logging import log_message\n",
        "from utils.data_and_files.file_utils import get_file_path\n",
        "\n",
        "class ImageIterator(Iterator):\n",
        "    \"\"\"Iterator capable of reading images from a directory on disk.\n",
        "\n",
        "    # Arguments\n",
        "        image_lists: Dictionary of training images for each label.\n",
        "        image_data_generator: Instance of `ImageDataGenerator`\n",
        "            to use for random transformations and normalization.\n",
        "        target_size: tuple of integers, dimensions to resize input images to.\n",
        "        color_mode: One of `\"rgb\"`, `\"grayscale\"`. Color mode to read images.\n",
        "        classes: Optional list of strings, names of sudirectories\n",
        "            containing images from each class (e.g. `[\"dogs\", \"cats\"]`).\n",
        "            It will be computed automatically if not set.\n",
        "        class_mode: Mode for yielding the targets:\n",
        "            `\"binary\"`: binary targets (if there are only two classes),\n",
        "            `\"categorical\"`: categorical targets,\n",
        "            `\"sparse\"`: integer targets,\n",
        "            `None`: no targets get yielded (only input images are yielded).\n",
        "            `episode`: a sequence of images yielded (with time shift).\n",
        "            `func`: custom transformation gets the input images and the transformed.\n",
        "\n",
        "        batch_size: Integer, size of a batch.\n",
        "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
        "        seed: Random seed for data shuffling.\n",
        "        data_format: String, one of `channels_first`, `channels_last`.\n",
        "        save_to_dir: Optional directory where to save the pictures\n",
        "            being yielded, in a viewable format. This is useful\n",
        "            for visualizing the random transformations being\n",
        "            applied, for debugging purposes.\n",
        "        save_prefix: String prefix to use for saving sample\n",
        "            images (if `save_to_dir` is set).\n",
        "        save_format: Format to use for saving sample images\n",
        "            (if `save_to_dir` is set).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 image_lists,\n",
        "                 image_data_generator,\n",
        "                 category, image_dir,\n",
        "                 target_size=(256, 256, 3),\n",
        "                 color_mode='rgb',\n",
        "                 class_mode='categorical',\n",
        "                 batch_size=32,\n",
        "                 episode_len=20,\n",
        "                 episode_shift=10,\n",
        "                 shuffle=True,\n",
        "                 seed=None,\n",
        "                 data_format=None,\n",
        "                 save_to_dir=None,\n",
        "                 save_prefix='',\n",
        "                 save_format='jpeg',\n",
        "                 dtype=K.floatx()\n",
        "                 ):\n",
        "        if data_format is None:\n",
        "            data_format = K.image_data_format()\n",
        "\n",
        "        classes = list(image_lists.keys())\n",
        "        self.category = category\n",
        "        self.batch_size = batch_size\n",
        "        self.num_class = len(classes)\n",
        "        self.image_lists = image_lists\n",
        "        self.image_dir = image_dir\n",
        "        self.episode_len = episode_len\n",
        "        self.episode_shift = episode_shift\n",
        "\n",
        "        how_many_files = 0\n",
        "        for label_name in classes:\n",
        "            for _ in self.image_lists[label_name][category]:\n",
        "                how_many_files += 1\n",
        "\n",
        "        self.samples = how_many_files\n",
        "        self.class2id = dict(zip(classes, range(len(classes))))\n",
        "        self.id2class = dict((v, k) for k, v in self.class2id.items())\n",
        "        self.classes = np.zeros((self.samples,), dtype='int32')\n",
        "\n",
        "        self.image_data_generator = image_data_generator\n",
        "        self.target_size = tuple(target_size)\n",
        "        if color_mode not in {'rgb', 'grayscale'}:\n",
        "            raise ValueError('Invalid color mode:', color_mode,\n",
        "                             '; expected \"rgb\" or \"grayscale\".')\n",
        "        self.color_mode = color_mode\n",
        "        self.data_format = data_format\n",
        "        self.image_shape = self.target_size\n",
        "\n",
        "        if (class_mode not in {'categorical', 'binary', 'sparse', 'episode', 'episode_flat', None}) and (not hasattr(class_mode, '__call__')):\n",
        "            raise ValueError('Invalid class_mode:', class_mode,\n",
        "                             '; expected one of \"categorical\", '\n",
        "                             '\"binary\", \"sparse\", \"episode\", or None.')\n",
        "        self.class_mode = class_mode\n",
        "        self.dtype = dtype\n",
        "        self.save_to_dir = save_to_dir\n",
        "        self.save_prefix = save_prefix\n",
        "        self.save_format = save_format\n",
        "\n",
        "        i = 0\n",
        "        self.filenames = []\n",
        "        for label_name in classes:\n",
        "            for j, _ in enumerate(self.image_lists[label_name][category]):\n",
        "                self.classes[i] = self.class2id[label_name]\n",
        "                img_path = get_file_path(self.image_lists,\n",
        "                                          label_name,\n",
        "                                          j,\n",
        "                                          self.image_dir,\n",
        "                                          self.category)\n",
        "                self.filenames.append(img_path)\n",
        "                i += 1\n",
        "        log_message(\"Found {} {} files\".format(len(self.filenames), category), logging.INFO)\n",
        "        Iterator.__init__(self, self.samples, self.batch_size, shuffle, seed)\n",
        "\n",
        "    def _get_batches_of_transformed_samples(self, index_array):\n",
        "        \"\"\"For python 2.x.\n",
        "\n",
        "        # Returns\n",
        "            The next batch.\n",
        "        \"\"\"\n",
        "        # with self.lock:\n",
        "        #    index_array, current_index, current_batch_size = next(self.index_generator)\n",
        "\n",
        "        # The transformation of images is not under thread lock\n",
        "        # so it can be done in parallel\n",
        "\n",
        "        if len(index_array) < self.batch_size:\n",
        "            diff = self.batch_size//len(index_array) + 1\n",
        "            index_array = np.repeat(index_array, diff, axis=0)[:self.batch_size]\n",
        "\n",
        "        grayscale = self.color_mode == 'grayscale'\n",
        "        if self.class_mode == 'episode':\n",
        "            batch_x = np.zeros((len(index_array), self.episode_len) + self.image_shape, dtype=self.dtype)\n",
        "            batch_gt = np.zeros((len(index_array), self.episode_len) + self.image_shape, dtype=self.dtype)\n",
        "\n",
        "            def get_filename(path):\n",
        "                folder, file = path.split(os.path.sep)[-2:]\n",
        "                file_name = file.split('.')[0]\n",
        "                return folder, int(file_name)\n",
        "\n",
        "\n",
        "            sorted_filenames = sorted(self.filenames, key=lambda f: get_filename(f))\n",
        "\n",
        "            max_ix = int(get_filename(sorted_filenames[-1])[1])\n",
        "            last_ix = max_ix - (self.episode_len + self.episode_shift)\n",
        "\n",
        "            # build batch of image data\n",
        "            for i, j in enumerate(index_array):\n",
        "                if j > last_ix:\n",
        "                    j = j - last_ix\n",
        "\n",
        "                imgs = []\n",
        "                for ix in range(j, j+self.episode_len):\n",
        "                    imgs += [\n",
        "                        self.image_data_generator.standardize(\n",
        "                            img_to_array(\n",
        "                                load_img(\n",
        "                                    sorted_filenames[ix],\n",
        "                                    grayscale=grayscale,\n",
        "                                    target_size=self.target_size\n",
        "                                ),\n",
        "                                data_format=self.data_format\n",
        "                            )\n",
        "                        )\n",
        "                    ]\n",
        "                imgs = np.array(imgs)\n",
        "                batch_x[i] = imgs\n",
        "\n",
        "                imgs = []\n",
        "                for ix in range(j+self.episode_shift, j+self.episode_len+self.episode_shift):\n",
        "                    imgs += [\n",
        "                        self.image_data_generator.standardize(\n",
        "                            img_to_array(\n",
        "                                load_img(\n",
        "                                    sorted_filenames[ix],\n",
        "                                    grayscale=grayscale,\n",
        "                                    target_size=self.target_size\n",
        "                                ),\n",
        "                                data_format=self.data_format\n",
        "                            )\n",
        "                        )\n",
        "                    ]\n",
        "\n",
        "                imgs = np.array(imgs)\n",
        "                batch_gt[i] = imgs\n",
        "            return batch_x, batch_gt\n",
        "\n",
        "        elif self.class_mode == 'episode_flat':\n",
        "            batch_x = np.zeros((len(index_array), self.episode_len) + self.image_shape, dtype=self.dtype)\n",
        "            batch_gt = np.zeros((len(index_array), self.episode_len) + self.image_shape, dtype=self.dtype)\n",
        "\n",
        "            def get_filename(path):\n",
        "                folder, file = path.split(os.path.sep)[-2:]\n",
        "                file_name = file.split('.')[0]\n",
        "                return folder, int(file_name)\n",
        "\n",
        "            sorted_filenames = sorted(self.filenames, key=lambda f: get_filename(f))\n",
        "\n",
        "            max_ix = int(get_filename(sorted_filenames[-1])[1])\n",
        "            last_ix = max_ix - (self.episode_len + self.episode_shift)\n",
        "\n",
        "            # build batch of image data\n",
        "            for i, j in enumerate(index_array):\n",
        "                if j > last_ix:\n",
        "                    j = j - last_ix\n",
        "\n",
        "                imgs = []\n",
        "                for ix in range(j, j + self.episode_len):\n",
        "                    imgs += [\n",
        "                        self.image_data_generator.standardize(\n",
        "                            img_to_array(\n",
        "                                load_img(\n",
        "                                    sorted_filenames[ix],\n",
        "                                    grayscale=grayscale,\n",
        "                                    target_size=self.target_size\n",
        "                                ),\n",
        "                                data_format=self.data_format\n",
        "                            )\n",
        "                        )\n",
        "                    ]\n",
        "                imgs = np.array(imgs)\n",
        "                batch_x[i] = imgs\n",
        "\n",
        "                imgs = []\n",
        "                for ix in range(j + self.episode_shift, j + self.episode_len + self.episode_shift):\n",
        "                    imgs += [\n",
        "                        self.image_data_generator.standardize(\n",
        "                            img_to_array(\n",
        "                                load_img(\n",
        "                                    sorted_filenames[ix],\n",
        "                                    grayscale=grayscale,\n",
        "                                    target_size=self.target_size\n",
        "                                ),\n",
        "                                data_format=self.data_format\n",
        "                            )\n",
        "                        )\n",
        "                    ]\n",
        "\n",
        "                imgs = np.array(imgs)\n",
        "                batch_gt[i] = imgs\n",
        "            return np.reshape(batch_x, (-1,)+self.image_shape ), np.reshape(batch_gt, (-1,)+self.image_shape)\n",
        "        else:\n",
        "            batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n",
        "            # build batch of image data\n",
        "            for i, j in enumerate(index_array):\n",
        "                img = load_img(self.filenames[j],\n",
        "                               grayscale=grayscale,\n",
        "                               target_size=self.target_size)\n",
        "                x = img_to_array(img, data_format=self.data_format)\n",
        "                x = self.image_data_generator.random_transform(x)\n",
        "                x = self.image_data_generator.standardize(x)\n",
        "                batch_x[i] = x\n",
        "\n",
        "            # optionally save augmented images to disk for debugging purposes\n",
        "            if self.save_to_dir:\n",
        "                for i, j in enumerate(index_array):\n",
        "                    img = array_to_img(batch_x[i], self.data_format, scale=True)\n",
        "                    fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n",
        "                                                                      index=j,\n",
        "                                                                      hash=np.random.randint(10000),\n",
        "                                                                      format=self.save_format)\n",
        "                    img.save(os.path.join(self.save_to_dir, fname))\n",
        "            # build batch of labels\n",
        "            if self.class_mode == 'sparse':\n",
        "                batch_y = self.classes[index_array]\n",
        "            elif self.class_mode == 'binary':\n",
        "                batch_y = self.classes[index_array].astype(K.floatx())\n",
        "            elif self.class_mode == 'categorical':\n",
        "                batch_y = np.zeros((len(batch_x), self.num_class),dtype=K.floatx())\n",
        "                for i, label in enumerate(self.classes[index_array]):\n",
        "                    batch_y[i, label] = 1.\n",
        "\n",
        "            elif self.class_mode is None:\n",
        "                return batch_x\n",
        "            else:\n",
        "                return batch_x, self.class_mode(batch_x)\n",
        "            return batch_x, batch_y\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}